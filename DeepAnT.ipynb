{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60oNtF4FWakJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling1D, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9A1LKB0GwtQH"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCvn51nkpuah"
   },
   "outputs": [],
   "source": [
    "              \"\"\"Hyperparameters\"\"\"\n",
    "w = 17280-500                 # History window (number of time stamps taken into account) \n",
    "                         # i.e., filter(kernel) size       \n",
    "p_w = 500                # Prediction window (number of time stampes required to be \n",
    "                         # predicted)\n",
    "n_features = 1           # Univariate time series\n",
    "\n",
    "kernel_size = 2          # Size of filter in conv layers\n",
    "num_filt_1 = 32          # Number of filters in first conv layer\n",
    "num_filt_2 = 32          # Number of filters in second conv layer\n",
    "num_nrn_dl = 40          # Number of neurons in dense layer\n",
    "num_nrn_ol = p_w        # Number of neurons in output layer\n",
    "\n",
    "conv_strides = 1\n",
    "pool_size_1 = 2          # Length of window of pooling layer 1\n",
    "pool_size_2 = 2          # Length of window of pooling layer 2\n",
    "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
    "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
    "\n",
    "epochs = 30\n",
    "dropout_rate = 0.5       # Dropout rate in the fully connected layer\n",
    "learning_rate = 2e-5  \n",
    "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "aKYzBd94KZFu",
    "outputId": "52cfaed6-92e1-42ab-8ce8-9e4af7cf69b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdf_helper import *\n",
    "from stat_helper import *\n",
    "from data_cleaning import *\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/datch_3.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "df_test = pd.read_csv('data/dat_ch_3_no_outliers.csv', nrows=100)\n",
    "\n",
    "float_cols = [c for i, c in enumerate(df_test.columns) if i != 0]\n",
    "float64_cols = {c: np.float64 for c in float_cols}\n",
    "\n",
    "df = pd.read_csv('data/datch_3.csv', engine='c', dtype=float64_cols).drop(['Unnamed: 0'], axis = 1)\n",
    "df = df.replace(np.NAN, 0.0)\n",
    "\n",
    "zero_outliers = df.loc[:, (df == 0.0).all(axis=0)]\n",
    "reg_data = df.loc[:,(df != 0.0).any(axis=0)]\n",
    "\n",
    "#df = reduce_dataset_size(df, cluster_size = 50)\n",
    "df = smooth_values(df)\n",
    "scaler = RobustScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = len(df.index) - 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQsOxuDCIGpQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data preprocessing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + w\n",
    "        out_end_ix = end_ix + p_w\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(27, 1, 16780)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n",
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# # define input sequence\n",
    "# for col in reg_data.columns:\n",
    "#     sampl, labl = split_sequence(list(reg_data[col]))\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "batch_sampl, batch_labl = split_sequence(list(reg_data.ix[:,0]))\n",
    "samples.append(batch_sampl)\n",
    "labels.append(batch_labl)\n",
    "\n",
    "print()\n",
    "\n",
    "for i in range(1, len(reg_data.columns)):\n",
    "    batch_sampl, batch_labl = split_sequence(list(reg_data.ix[:,i]))\n",
    "    samples.append(batch_sampl)\n",
    "    labels.append(batch_labl)\n",
    "    \n",
    "batch_sample = np.array(samples)\n",
    "batch_label = np.array(labels)\n",
    "    \n",
    "print(batch_sample.shape)\n",
    "\n",
    "# summarize the data\n",
    "# for i in range(5):\n",
    "#     print(X[i], Y[i])\n",
    "  \n",
    "# 2. reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "\n",
    "# need to convert batch into 3D tensor of the form [batch_size, input_seq_len, n_features]\n",
    "batch_sample = batch_sample.reshape((batch_sample.shape[0], batch_sample.shape[2], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 1, 500)\n",
      "(27, 16780, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_label = batch_label.reshape((batch_label.shape[0],batch_label.shape[1],batch_label.shape[2]))\n",
    "print(batch_label.shape)\n",
    "print(batch_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "colab_type": "code",
    "id": "sLBqHZLmomSD",
    "outputId": "375909cf-8a14-4e10-aa93-7d5d2fac440a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_38 (Conv1D)           (None, 16779, 32)         96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 8389, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 8388, 32)          2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 4194, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 134208)            0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 40)                5368360   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 500)               20500     \n",
      "=================================================================\n",
      "Total params: 5,391,036\n",
      "Trainable params: 5,391,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "              \"\"\"Generate model for predictor\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer #1\n",
    "# Computes 32 features using a 1D filter(kernel) of with w with ReLU activation. \n",
    "# Padding is added to preserve width.\n",
    "# Input Tensor Shape: [batch_size, w, 1] / batch_size = len(batch_sample)\n",
    "# Output Tensor Shape: [batch_size, w, num_filt_1] (num_filt_1 = 32 feature vectors)\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "\n",
    "# Pooling Layer #1\n",
    "# First max pooling layer with a filter of length 2 and stride of 2\n",
    "# Input Tensor Shape: [batch_size, w, num_filt_1]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1]\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "                    #  strides=pool_strides_1, \n",
    "                    #  padding='valid'))\n",
    "\n",
    "# Convolutional Layer #2\n",
    "# Computes 64 features using a 5x5 filter.\n",
    "# Padding is added to preserve width and height.\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, 32]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "# Max Pooling Layer #2\n",
    "# Second max pooling layer with a 2x2 filter and stride of 2\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "                    #  strides=pool_strides_2, \n",
    "                    #  padding='valid'\n",
    "          \n",
    "# Flatten tensor into a batch of vectors\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer (Output layer)\n",
    "# Densely connected layer with 1024 neurons\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 1024]\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu'))  \n",
    "\n",
    "# Dropout\n",
    "# Prevents overfitting in deep neural networks\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Output layer\n",
    "# Input Tensor Shape: [batch_size, 1024]\n",
    "# Output Tensor Shape: [batch_size, p_w]\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Summarize model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "K76R-2HPajxI",
    "outputId": "b138835d-a0e7-4af7-a1fd-53b18446258a"
   },
   "outputs": [],
   "source": [
    "                 '''configure model'''\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_absolute_error')\n",
    "\n",
    "# sgd = keras.optimizers.SGD(lr=learning_rate, \n",
    "#                          decay=1e-6, \n",
    "#                          momentum=0.9, \n",
    "#                          nesterov=True)\n",
    "# model.compile(optimizer='sgd', \n",
    "#               loss='mean_absolute_error', \n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MO8EMSBaMZ8K",
    "outputId": "7c033331-7d5e-473c-ac81-5c7971db6fa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel_fit = model.fit(batch_sample,\\n                      batch_label,\\n                      epochs=epochs,\\n                      verbose=1)\\n'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "model_fit = model.fit(batch_sample,\n",
    "                      batch_label,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.1092\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1727\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1107\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0186\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0028\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0017\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.9658e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.7294e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.4511e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.4059e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.1767e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.4507e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.5444e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.3574e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.0828e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.5047e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.8884e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.4244e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.2098e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.6904e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1626e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.4772e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.3835e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0678e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0499\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0209\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0214\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0016\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.1127e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.2640e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.8274e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.9648e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.9761e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.1213e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.6077e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.6260e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5092e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.2622e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.2652e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.1950e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0895e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.9127e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.7327e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5910e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.4872e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.4475e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.3171e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2425e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2224e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.8841e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7311e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.8768e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.9839e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.8943e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0031\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.3057e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0016\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.9511e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.9370e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.7044e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2249e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.9365e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.9051e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.9223e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.9243e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9514e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.9041e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.7231e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.6497e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5956e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5559e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.5471e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.6321e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4824e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3943e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4891e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4940e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4450e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3801e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3423e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3745e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3368e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3813e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4071e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1020\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0436\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2283e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.6189e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.4163e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.9465e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.3662e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2019e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2409e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.1871e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.1275e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.1221e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.0056e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.0189e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.0560e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.9012e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.7924e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6914e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.6049e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.5599e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6895e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.7082e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6670e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6218e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3776e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2901e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4052e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5266e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5105e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3476e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4005e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4046e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.5152e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4965e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3486e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2984e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2834e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3964e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4390e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3721e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3503e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3137e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3030e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2982e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3258e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3396e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4481e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4047e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3654e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3062e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2517e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2705e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3621e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3077e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1996e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2207e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3742e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3800e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3284e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2266e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 40.9086\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.9123e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.1244e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.5373\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.4731e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.4726e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2108e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8679e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6020e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5775e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7837e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.8190e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.7999e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.7258e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4970e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4818e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.6042e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5356e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4561e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4391e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3186e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3570e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4639e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4232e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3851e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3431e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2901e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2399e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3406e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3906e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5071\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5071\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5070\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5070\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5071\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5070\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5070\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5070\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5070\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5070\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5070\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5070\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5070\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5070\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5070\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5070\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5070\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5070\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5070\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5070\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5070\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5069\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5069\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5069\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5069\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5069\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5069\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 15.4714\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3773\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 15.3773\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 15.3772\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 15.3771\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 15.3770\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 15.3769\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3768\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 15.3767\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15.3766\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15.3764\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15.3763\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3761\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 15.3760\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15.3758\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 15.3757\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3755\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3754\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15.3752\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3750\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 15.3749\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 15.3747\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 15.3745\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3743\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 15.3742\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15.3740\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 15.3738\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 15.3736\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15.3735\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 15.3733\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2245\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.2246\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2247\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2247\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2247\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2247\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2247\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2247\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2246\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2245\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2244\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.2243\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2242\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2241\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2239\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2238\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2237\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2235\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2234\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2232\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2230\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2229\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2227\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2225\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2223\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2221\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2219\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2218\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2216\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.2214\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0022\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1132\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0013\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.2066e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.0041e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.4784e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0011\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.9750e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.2293e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.3666e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.5427e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.7853e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.1206e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.7934e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.7061e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7275e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.7550e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5819e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.1120e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.5356e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.0169e-04\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step - loss: 3.6719e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.4427e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2113e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.9152e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.6122e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.3052e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.1159e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8832e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8511e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.9157e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.9636e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0021e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.0871e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.0900e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.0874e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.0736e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.9927e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8801e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8190e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.7794e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6755e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5426e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.5365e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4693e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4836e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5801e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6719e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5749e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4651e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3788e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4530e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4340e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3239e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3024e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3562e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3863e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2915e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2307e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2700e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2873e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3268e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3131e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2928e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2611e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3102e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2855e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2792e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2299e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1694e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2335e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2719e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2450e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2554e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1972e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2061e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2395e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2357e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2124e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1980e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1345e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1012e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1913e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2658e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1678e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1507e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2176e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2709e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1999e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1661e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1576e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1636e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1518e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1470e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1907e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2197e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2479e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2553e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1690e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2131e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2535e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2644e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2023e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1830e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1188e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1227e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1321e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2198e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1813e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1054e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1488e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1474e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1678e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1481e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1105e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1295e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1525e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1942e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2022e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2516e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2195e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2175e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2207e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2278e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1827e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1825e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1835e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2218e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1833e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1325e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1318e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2094e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2058e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1694e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1402e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1503e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2038e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2412e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1565e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1637e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1966e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1842e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2375e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2561e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1611e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1574e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1672e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2214e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1518e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1331e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1835e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2033e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1815e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1268e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1224e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2050e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2117e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2190e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1460e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1379e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1590e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2063e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1556e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1470e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1254e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0703e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1750e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2186e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1926e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1850e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1526e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1825e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2568e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2507e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1667e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2258e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2470e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2193e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1603e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1878e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1838e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1610e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1581e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1412e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1520e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1755e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1626e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2230e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1047e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0907e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1705e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2332e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1862e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1461e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1468e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1596e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1918e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2171e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2142e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2103e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1831e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1664e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1735e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2036e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1261e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1414e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1922e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2243e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2030e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2042e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1455e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1284e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1795e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2046e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1856e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2170e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2343e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2180e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1377e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1812e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1778e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1244e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1661e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1769e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1079e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0997e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1606e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3068e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2300e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1543e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1741e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2094e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1906e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1710e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1623e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1541e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2296e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2186e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2034e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1760e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2310e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2733e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1704e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1855e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1689e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2172e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1706e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2085e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1681e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1192e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1376e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1789e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1658e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1584e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1752e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1355e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1489e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2006e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1896e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2025e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1394e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1177e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2493e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2638e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1502e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1340e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1616e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2113e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1571e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1259e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1221e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1760e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1715e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1178e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1002e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1536e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1775e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1700e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1612e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1565e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1665e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1923e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1645e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1854e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1709e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1449e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1849e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2403e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1721e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1348e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1150e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1648e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2078e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1739e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1148e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1530e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2319e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2229e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1932e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2212e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1644e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1996e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2109e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2253e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1719e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1137e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1364e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2038e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1444e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0446e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1134e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1878e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2052e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2158e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0972e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1325e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2011e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2355e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2016e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1835e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1753e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1909e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2253e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2157e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1944e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2267e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2021e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1973e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2060e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1960e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1645e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2046e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1568e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1471e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1875e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2524e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2143e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1490e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1342e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1447e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1661e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2137e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1922e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2058e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1245e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0813e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1317e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2250e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1826e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1313e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1813e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2067e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2469e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2437e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1423e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1983e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2535e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2459e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1687e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1811e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1890e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2269e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2038e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1570e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1736e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2170e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2446e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2355e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1357e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1562e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1757e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2885e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2228e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1655e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1866e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1731e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2240e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2120e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1594e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1544e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2192e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1963e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1825e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1639e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1219e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1650e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1389e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1706e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1024e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1566e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2094e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1822e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1422e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1042e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1545e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2171e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2031e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1785e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1718e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1478e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1185e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1604e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1741e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2179e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1836e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1429e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1759e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2447e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2158e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1931e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1446e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1900e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2442e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2309e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1431e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1631e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1696e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1012e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1104e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1613e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1806e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1564e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1256e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1425e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1486e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2132e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1610e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1895e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1456e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1372e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1858e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2157e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2010e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1839e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1588e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1452e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1993e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2176e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1756e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1525e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1358e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1539e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1230e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1737e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1248e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0836e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1867e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2108e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1485e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1835e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2033e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2529e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2156e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1260e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1724e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2685e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2028e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1681e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1458e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1734e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2018e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2699e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2135e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1424e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1471e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1394e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1355e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1674e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1453e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1354e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1238e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1118e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1364e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1460e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0843e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1336e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1510e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1760e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2288e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2267e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1928e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2071e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1851e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2235e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1694e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1628e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2283e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2598e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2031e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0897e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0785e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2198e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2941e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2390e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1327e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1445e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2155e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2384e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1401e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1071e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1131e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1308e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1652e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1532e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1067e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1140e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1795e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1894e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1239e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1726e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1754e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2052e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1250e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1129e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1399e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2473e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2575e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1838e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1859e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1624e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1953e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2530e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1990e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1900e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1510e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1214e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1454e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1654e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0771e-04\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reg_data.columns)):\n",
    "    sampl = batch_sample[i].reshape((1,batch_sample.shape[1],batch_sample.shape[2]))\n",
    "    print(sampl.shape)\n",
    "    labl = batch_label[i].reshape((batch_label.shape[1],batch_label.shape[2]))\n",
    "    model.fit(sampl,\n",
    "                          labl,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "URqDB0oxhX_X",
    "outputId": "35e8073b-7b4e-4098-f5e7-0f000124a0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00010754847608041018"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                 \"\"\"Testing with random interval(DeepAnT)\"\"\"\n",
    "# Set number of test sequences \n",
    "n_test_seq = 1\n",
    "\n",
    "# Split a univariate sequence into samples\n",
    "def generate_test_batch(raw_seq, n_test_seq):\n",
    "  # Sample a portion of the raw_seq randomly\n",
    "    ran_ix = random.randint(0,len(raw_seq) - n_test_seq * w - n_test_seq * p_w)\n",
    "    raw_test_seq = array(raw_seq[ran_ix:ran_ix + n_test_seq * w +  n_test_seq * p_w])\n",
    "    batch_test_seq, batch_test_label = list(), list()\n",
    "    ix = ran_ix\n",
    "    for i in range(n_test_seq):\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = raw_seq[ix : ix+w],\n",
    "        seq_y = raw_seq[ix+w : ix+w+p_w]\n",
    "        ix = ix+w+p_w\n",
    "        batch_test_seq.append(seq_x)\n",
    "        batch_test_label.append(seq_y)\n",
    "    return array(batch_test_seq), array(batch_test_label)\n",
    "\n",
    "batch_test_seq, batch_test_label = generate_test_batch(list(reg_data.ix[:,0]), n_test_seq)\n",
    "batch_test_seq = batch_test_seq.reshape((batch_test_seq.shape[0], w, n_features))\n",
    "batch_test_label = batch_test_label.reshape((batch_test_label.shape[0], p_w))\n",
    "\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "model.evaluate(x=batch_test_seq,\n",
    "               y=batch_test_label,\n",
    "               verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK0_Cq-Oh0tC"
   },
   "outputs": [],
   "source": [
    "               \"\"\"Save Weights (DeepAnT)\"\"\"\n",
    "# save it to disk so we can load it back up anytime\n",
    "model.save_weights('ch_3_noanom_weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jpzknk4th9bU",
    "outputId": "ab1c4808-b829-4bd7-8d65-2e273a6e70b1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2-oM2iL1gw4Q",
    "outputId": "a8ac362e-fccd-4d6c-f946-386a27620206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 176ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.85183904e-04 -1.32300935e-04 -8.82727254e-05 -2.06019002e-04\n",
      "  -7.72617059e-05 -8.07969627e-06  7.83204596e-05  5.02749717e-05\n",
      "   1.30865679e-04 -1.04726525e-04 -3.85911444e-05  4.33041823e-05\n",
      "  -3.46729968e-04  6.74767653e-05 -2.13790729e-04 -2.09147765e-05\n",
      "  -1.46992825e-05  1.43535173e-04 -2.69379234e-05  1.49465151e-04\n",
      "  -2.15686727e-04 -2.33890009e-04 -5.65348892e-05 -1.46870138e-04\n",
      "  -1.31546811e-04  4.19120188e-05 -7.20985845e-05  2.03742893e-05\n",
      "  -4.75385605e-05  8.93800243e-05 -2.43909788e-04 -3.86440734e-05\n",
      "  -1.82419899e-04  1.31043213e-04  2.40865629e-05  2.17484398e-04\n",
      "  -7.01624522e-05  7.74110958e-05  3.00932297e-05 -9.30283422e-05\n",
      "  -1.21966601e-04 -4.31240333e-05  1.63763631e-04 -8.96870915e-05\n",
      "   2.18394416e-06  2.97621329e-04  2.69305092e-05  6.74377661e-05\n",
      "   2.11242077e-05  3.22300592e-04  1.91093437e-04  5.46322917e-05\n",
      "  -5.48667158e-05  2.00628201e-04 -4.17526826e-05 -2.44296796e-04\n",
      "  -3.16652702e-04  9.19835293e-06  1.37313051e-04 -1.02308171e-04\n",
      "   1.84740507e-04  1.82154472e-05  8.77422572e-05  3.65761807e-05\n",
      "   1.16382871e-04 -2.22985982e-05  4.28312254e-04 -9.13457116e-05\n",
      "  -3.22505599e-04  1.34935894e-04 -9.33262854e-05 -5.39308603e-05\n",
      "   2.74501770e-04  2.54063722e-04 -1.90782725e-04 -1.69226594e-04\n",
      "   6.25826651e-05  1.17196178e-04 -3.07457696e-04  1.57424525e-04\n",
      "  -1.11182671e-04 -1.15574876e-05  1.59692991e-06 -1.10272958e-04\n",
      "  -2.54565930e-06  1.37238196e-04  9.84170183e-05  4.36875998e-05\n",
      "  -8.59381453e-06 -6.08260525e-05 -6.44859902e-05 -1.14407769e-04\n",
      "  -1.11885223e-04 -7.21384822e-06  6.23123778e-05 -1.67179838e-04\n",
      "   1.29529129e-04  2.05961376e-04  3.41251434e-05  1.48452906e-04\n",
      "   7.04751292e-05 -1.57026734e-04  9.61390469e-07  4.09951972e-05\n",
      "   5.95699894e-05  2.00284732e-04 -7.32883927e-05 -1.83228985e-06\n",
      "  -4.04889361e-05  2.12545492e-05  3.18948150e-05 -2.05793112e-04\n",
      "  -1.05264829e-04  1.34232905e-04  5.23142808e-05 -2.62117625e-04\n",
      "  -1.14467461e-04 -5.56936211e-05 -1.11298186e-05  5.66983363e-05\n",
      "   1.93310072e-04 -1.27887470e-04 -2.30259611e-05  1.12377747e-04\n",
      "  -1.86956589e-04 -6.72706665e-05 -1.06450309e-04 -1.76290501e-04\n",
      "  -2.87940260e-04 -4.45618207e-05  1.08436521e-04 -3.44354543e-04\n",
      "   4.89852209e-05  1.52739492e-04 -1.25408129e-04  5.03685260e-05\n",
      "  -5.64894290e-05 -4.15117756e-05 -8.80500884e-05  2.59830686e-05\n",
      "  -1.09411900e-04 -1.46694365e-05  1.00362471e-04  1.39440584e-04\n",
      "   8.79065483e-05  3.88720728e-05 -9.58296441e-05 -1.14407434e-04\n",
      "  -7.48543825e-05 -6.13549309e-06 -1.06458683e-05 -1.03724320e-04\n",
      "   1.99796137e-04  1.03621569e-04 -2.23901588e-06 -1.08331042e-05\n",
      "   5.29553108e-05 -9.41256585e-05 -6.26947149e-05 -5.73927682e-05\n",
      "  -1.05335403e-05 -2.00291572e-04 -7.14259440e-05  6.99731754e-06\n",
      "   1.64318444e-05 -1.76653004e-04  2.19415058e-04 -1.49207175e-04\n",
      "  -8.11671853e-05  1.85342011e-04  1.99337708e-04  9.19290906e-05\n",
      "  -7.28714804e-06 -1.94527092e-04  2.50345620e-05 -4.87703946e-05\n",
      "  -1.30145636e-04 -1.31418055e-05  8.27684707e-05  1.79961702e-04\n",
      "  -1.21300924e-04  1.21996498e-04 -5.95098609e-05  1.99102815e-05\n",
      "  -8.76984122e-05 -1.29199179e-04  3.23996384e-04 -2.06371406e-04\n",
      "   8.48426353e-05 -1.39732350e-04  1.15627117e-04  1.11416331e-04\n",
      "   1.13254267e-04 -9.23195912e-05 -4.58533032e-06 -9.23271728e-07\n",
      "   3.69873305e-06 -1.40334261e-04 -1.11145848e-04 -2.16521403e-06\n",
      "   7.77883542e-05 -2.75490776e-04  2.01550938e-04 -1.60322204e-04\n",
      "  -1.42794204e-04  5.52241218e-05  1.28449712e-04 -1.60679774e-05\n",
      "   2.65172916e-04  8.47936462e-07  1.60967902e-04 -1.80481613e-04\n",
      "  -2.78174441e-04 -1.56882306e-05 -2.46005147e-05  9.14818702e-06\n",
      "   8.12226790e-05  5.06370779e-05 -4.22649373e-06 -1.02482787e-04\n",
      "   5.36048683e-05 -1.89555503e-04 -6.75503688e-05 -8.82054519e-05\n",
      "   1.13883114e-04 -1.38157309e-04 -1.90656210e-04 -6.37833436e-05\n",
      "  -1.27142208e-04  1.48064173e-05 -1.63254474e-04  1.59082701e-05\n",
      "  -3.87388718e-05  2.26973134e-06  4.87085308e-05  1.47101062e-04\n",
      "  -7.39620300e-05 -1.50470572e-04 -6.25049433e-05  4.01176258e-05\n",
      "  -2.32371349e-06  4.17253381e-04  1.94081222e-04 -5.85861635e-05\n",
      "   2.03166244e-04  6.88374857e-05 -2.27165583e-06 -1.69601582e-04\n",
      "   7.09766973e-05  6.42153900e-05 -1.14445342e-04 -9.57335724e-05\n",
      "  -1.07008178e-04 -1.48506908e-04  6.23837404e-05 -3.85887368e-04\n",
      "  -3.67188914e-05  2.29206547e-04  1.41539422e-05 -4.59648545e-05\n",
      "   1.05142950e-04 -2.63502909e-04 -1.45686106e-04 -1.59740011e-07\n",
      "   1.79671391e-04  1.14328468e-05  3.15711921e-04 -4.73173095e-05\n",
      "  -7.59064424e-05 -2.12508276e-05 -1.45788086e-04 -4.41021984e-05\n",
      "  -2.37111817e-06  4.15419236e-05 -5.71203855e-05 -3.47913214e-04\n",
      "  -1.41388055e-05  1.35946888e-04  1.27234904e-04 -8.00462585e-05\n",
      "  -1.37086128e-04  1.48767431e-04 -1.53375775e-04  1.41310549e-04\n",
      "  -4.75194538e-05  2.21257593e-04  1.00948913e-04 -8.90763404e-05\n",
      "  -1.40444026e-05 -3.76787239e-06  1.94562512e-04  4.68914041e-05\n",
      "   1.55721063e-05  8.65382317e-05  8.09764679e-05  6.35062133e-06\n",
      "  -3.07731039e-04 -1.85083467e-04 -2.04299286e-05  2.80449003e-05\n",
      "  -2.10056169e-06 -4.96336143e-05  6.95936615e-05  4.63214383e-05\n",
      "  -2.87247094e-05  3.11443218e-05 -6.93125821e-06 -3.73049625e-06\n",
      "  -2.03760617e-04  6.75738047e-05 -1.17489079e-04 -1.79374823e-04\n",
      "  -9.12220275e-05 -8.63378009e-05 -1.15014394e-04  7.74332730e-05\n",
      "   1.73520821e-05 -9.02616448e-05 -4.51958513e-05 -1.59362942e-04\n",
      "   3.17270868e-04 -3.46804227e-05  5.78618128e-05 -3.80208221e-05\n",
      "   2.96190323e-04 -4.59155490e-05 -1.74634522e-04  1.10169211e-04\n",
      "   1.20877536e-04  2.49822915e-04 -1.68523839e-04 -2.30573714e-04\n",
      "   1.35543436e-04 -5.57550593e-05  4.22007724e-05 -4.72034844e-05\n",
      "   6.04814049e-05  5.11636244e-05 -1.41514858e-04 -1.60763535e-04\n",
      "  -1.42498266e-05 -9.61749975e-05 -1.57770075e-04  4.26918268e-05\n",
      "  -9.84940416e-05  5.24206880e-05 -3.76184908e-04 -1.68677871e-04\n",
      "   1.92807875e-05 -6.42122468e-05  7.12809560e-05 -3.32154887e-05\n",
      "  -1.83599608e-04  2.53237213e-05  2.79158448e-05  6.19068742e-05\n",
      "  -1.44895675e-04  8.71552038e-06 -7.23537232e-05  2.08753729e-04\n",
      "  -9.38546291e-05  1.28211221e-04 -3.78421973e-05  5.60031258e-05\n",
      "  -9.00047307e-05 -1.45908198e-05 -2.40322734e-05  1.40688178e-04\n",
      "  -1.04323997e-04  1.35777795e-04  6.88938089e-05 -7.31265609e-05\n",
      "   2.24292206e-04  7.11336543e-05  1.31469555e-04  1.74457760e-04\n",
      "  -2.06933601e-05 -2.02760144e-04 -6.86404455e-05 -1.16671101e-04\n",
      "   1.84841163e-04  5.68435062e-05 -1.32855945e-04  1.43039695e-04\n",
      "   1.49098196e-05 -9.40006648e-05 -7.92562205e-05  1.00063204e-04\n",
      "  -4.77949325e-05  3.67574794e-05  7.49706232e-05 -3.25422297e-05\n",
      "   1.29469816e-04 -3.31210904e-05 -1.00593228e-04  1.27556341e-04\n",
      "   1.59578427e-04  1.55029265e-04 -9.77427553e-05  1.56935857e-06\n",
      "  -4.17336443e-04 -2.46430078e-04  3.65575652e-05  4.50102016e-05\n",
      "  -3.04432215e-05 -3.13484197e-05 -9.22415347e-05 -2.45485979e-04\n",
      "  -6.87257270e-05 -1.16973315e-05  1.51838613e-04 -1.56398339e-04\n",
      "  -1.89231461e-04  8.43974994e-05  2.37362619e-05 -1.56434005e-04\n",
      "  -1.09112429e-04  8.39092681e-05 -8.88358190e-05  4.12955014e-05\n",
      "  -2.39847413e-05  5.64262336e-05  2.71339290e-04 -1.27579260e-04\n",
      "   1.07287415e-04  2.86256909e-05  6.16747711e-05  3.26353329e-05\n",
      "   4.58846589e-05  2.20622576e-04 -7.66855737e-05 -1.89463710e-04\n",
      "  -2.31849008e-05  1.08949360e-04 -8.85137852e-05  1.49519983e-04\n",
      "  -9.68006862e-06  8.61518856e-06  3.87635155e-05 -2.34907697e-04\n",
      "   1.27425432e-04 -1.85956851e-05 -1.86996185e-04 -9.81152334e-05\n",
      "   5.09758189e-04 -5.91046082e-05  8.74089019e-05 -1.46033271e-04\n",
      "   5.06931974e-06 -4.56632624e-05 -2.27599594e-04  2.77454761e-04\n",
      "  -2.67795695e-05 -1.85577403e-04  1.81865267e-04  7.00813252e-05\n",
      "  -4.02450445e-04 -1.80794596e-04 -1.04824008e-04  1.59196614e-04\n",
      "  -1.24215148e-07  4.51692467e-05  1.42232195e-04 -4.58847317e-05\n",
      "  -1.10110428e-04  8.99920560e-05 -1.61231103e-04  1.12967144e-04\n",
      "  -1.10330202e-05  1.21733028e-05 -1.76169691e-04 -2.24056257e-05\n",
      "   1.68361497e-04 -1.27154592e-04 -2.74396065e-04  2.88462063e-04\n",
      "   1.95244269e-04 -2.12725936e-04  1.26086059e-04 -1.63029923e-04\n",
      "   1.47138053e-04  8.46333423e-05 -3.91243462e-04  3.02580447e-05\n",
      "   1.30686312e-04  3.09894036e-04  2.13550156e-05 -1.78013957e-04\n",
      "  -5.79670559e-05 -1.72755987e-04  1.47881685e-04  2.73296901e-05\n",
      "  -9.53527051e-05  2.70012370e-05  7.35472859e-05  1.12467060e-04\n",
      "  -2.14602187e-06  6.60274818e-05 -7.21601100e-05 -2.06345110e-04]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "            \"\"\"Predicting future sequence (DeepAnT)\"\"\"\n",
    "# Build model \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('ch_3_noanom_weights.h5')\n",
    "          \n",
    "    \n",
    "raw_seq = list(reg_data.ix[:,0])\n",
    "endix = len(raw_seq) - w - p_w\n",
    "input_seq = array(raw_seq[endix:endix+w])\n",
    "target_seq = array(raw_seq[endix+w:endix+w+p_w]) \n",
    "input_seq = input_seq.reshape((1, w, n_features))\n",
    "\n",
    "# Predict the next time stampes of the sampled sequence\n",
    "predicted_seq = model.predict(input_seq, verbose=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(predicted_seq)\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(target_seq) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "664VO9gMmmFE",
    "outputId": "0f8b7983-5c1c-4b94-d898-865d8f0fc0fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7200x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "           '''Visualization of predicted time series'''\n",
    "in_seq = reg_data.ix[:,i][endix:endix+w]\n",
    "tar_seq = reg_data.ix[:,i][endix+w:endix+w+p_w]\n",
    "predicted_seq = predicted_seq.reshape((p_w))\n",
    "d = {'time': reg_data.ix[:,i][endix+w:endix+w+p_w], 'values': predicted_seq}\n",
    "df_sine_pre = pd.DataFrame(data=d)\n",
    "pre_seq = df_sine_pre['values']\n",
    "\n",
    "plt.plot(in_seq)\n",
    "plt.plot(tar_seq)\n",
    "plt.plot(pre_seq)\n",
    "plt.ylim(top=.05)\n",
    "plt.ylim(bottom=-.05)\n",
    "\n",
    "plt.title('Channel 3 Prediction')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('time')\n",
    "plt.legend(['input_seq', 'target_seq', 'pre_seq'], loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([endix,endix+w+p_w])\n",
    "fig_predict = plt.figure(figsize=(100,10))\n",
    "fig_predict.savefig('predicted_sequence.png')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "no2SqYbNoPXG",
    "outputId": "6925ffa8-9a85-4f10-99a9-f6dedb408878"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFv7f2x-euPk"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "            \"\"\"Predicting random intervals (DeepAnT)\"\"\"\n",
    "# Build model \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('ch_1_weights.h5')\n",
    "          \n",
    "# Sample a portion of the raw_seq randomly\n",
    "# 1. Choose \n",
    "ran_ix = random.randint(1,len(raw_seq) - w - p_w)\n",
    "input_seq = array(raw_seq[ran_ix : ran_ix + w])\n",
    "target_seq = array(raw_seq[ran_ix + w : ran_ix + w + p_w])\n",
    "input_seq = input_seq.reshape((1, w, n_features))\n",
    "\n",
    "# Predict the next time stampes of the sampled sequence\n",
    "yhat = model.predict(input_seq, verbose=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(yhat)\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(target_seq) # [7, 2, 1, 0, 4]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determins whether a sequence exceeds the threshold for being an anomaly\n",
    "\n",
    "return boolean value of whether the sequence is an anomaly or not\n",
    "\"\"\"\n",
    "def anomaly_detector(prediction_seq, ground_truth_seq):\n",
    "    # calculate Euclidean between actual seq and predicted seq\n",
    "    dist = np.linalg.norm(ground_truth_seq - prediction_seq)  \n",
    "    if (dist > anm_det_thr):\n",
    "        return true  # anomaly\n",
    "    else:\n",
    "        return false # normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda6f2bec422dd747988837f1b049720b89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
