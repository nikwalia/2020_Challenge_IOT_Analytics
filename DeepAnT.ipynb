{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAnT Implementation for Caterpillar IoT Machine Learning Challenge\n",
    "\n",
    "Model derived from: \n",
    "\n",
    "M. Munir, S. A. Siddiqui, A. Dengel and S. Ahmed, \"DeepAnT: A Deep Learning Approach for Unsupervised Anomaly Detection in Time Series,\" \n",
    "\n",
    "https://ieeexplore.ieee.org/document/8581424\n",
    "\n",
    "\n",
    "Implementation derived from:\n",
    "\n",
    "https://github.com/ZhouYuxuanYX/Unsupervised-Deep-Learning-Framework-for-Anomaly-Detection-in-Time-Series-\n",
    "https://github.com/hendrycks/outlier-exposure\n",
    "https://github.com/swlee23/Deep-Learning-Time-Series-Anaomaly-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60oNtF4FWakJ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling1D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from hdf_helper import *\n",
    "from stat_helper import *\n",
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9A1LKB0GwtQH"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCvn51nkpuah"
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS FOR OUR MODEL\n",
    "w = 17280                 # History window (Based off frequency and start/end time of timeseries)   \n",
    "p_w = 1000                # Prediction window (number of time stamps that we want to predict)\n",
    "n_features = 1            # Univariate time series (1D Array)\n",
    "\n",
    "kernel_size = 2          # Size of filter in convolutional layer\n",
    "num_filt_1 = 32          # Number of filters in first convolutional layer\n",
    "num_filt_2 = 32          # Number of filters in second convolutional layer\n",
    "num_nrn_dl = 40          # Number of neurons in dense layer\n",
    "num_nrn_ol = p_w         # Number of neurons in output layer\n",
    "\n",
    "conv_strides = 1\n",
    "pool_size_1 = 2          # Length of window of pooling layer 1\n",
    "pool_size_2 = 2          # Length of window of pooling layer 2\n",
    "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
    "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
    "\n",
    "epochs = 30\n",
    "dropout_rate = 0.5       # Dropout rate in the fully connected layer\n",
    "learning_rate = 2e-5  \n",
    "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)\n",
    "\n",
    "decay = 1e-6             # SGD Parameters\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file\n",
    "filename = 'dat_ch_3'\n",
    "path = 'dat/' + filename + '.csv'\n",
    "\n",
    "# Removing all columns that aren't float64 in order to read the dataframe properly\n",
    "df_test = pd.read_csv(path, nrows=100)\n",
    "float_cols = [c for i, c in enumerate(df_test.columns) if i != 0]\n",
    "float64_cols = {c: np.float64 for c in float_cols}\n",
    "df = pd.read_csv(path, engine='c', dtype=float64_cols).drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "df = df.replace(np.NAN, 0.0)\n",
    "\n",
    "# Remove all timeseries that are completely zero as to not throw off the model\n",
    "zero_outliers = df.loc[:, (df == 0.0).all(axis=0)]\n",
    "reg_data = df.loc[:,(df != 0.0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data preprocessing\n",
    "\n",
    "1. Downsample data using the mean of moving windws of size 50\n",
    "2. Use Gaussian blur to smooth out values\n",
    "3. Scale values based on IQR (robust scaler) to make them more workable with\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = reduce_dataset_size(df, cluster_size = 50)\n",
    "df = smooth_values(df)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df))\n",
    "\n",
    "# Subtract prediction window so we don't predict something we already know\n",
    "w = len(df.index) - p_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQsOxuDCIGpQ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Split our univariate sequence into samples\n",
    "'''\n",
    "def split_sequence(sequence):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + w\n",
    "        out_end_ix = end_ix + p_w\n",
    "        \n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "            \n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(27, 1, 16280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n",
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Defining the input sequence\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "# For every timeseries, append the split univeriate sequence to our batch_sample\n",
    "for i in range(len(reg_data.columns)):\n",
    "    batch_sample, batch_label = split_sequence(list(reg_data.ix[:,i]))\n",
    "    samples.append(batch_sample)\n",
    "    labels.append(batch_label)\n",
    "    \n",
    "batch_samples = np.array(samples)\n",
    "batch_labels = np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# We need to convert batch sample into 3D tensor because we are using multiple time series\n",
    "# batch_sample takes the form of [batch_size, input_seq_len, n_features]\n",
    "# batch_label takes the form of [number_batches, n_features, window_size]\n",
    "batch_sample = batch_sample.reshape((batch_sample.shape[0], batch_sample.shape[2], n_features))\n",
    "batch_label = batch_label.reshape((batch_label.shape[0],batch_label.shape[1],batch_label.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determins whether a sequence exceeds the threshold for being an anomaly\n",
    "\n",
    "return boolean value of whether the sequence is an anomaly or not\n",
    "\"\"\"\n",
    "def anomaly_detector(prediction_seq, ground_truth_seq):\n",
    "    # calculate Euclidean between actual seq and predicted seq\n",
    "    dist = np.linalg.norm(ground_truth_seq - prediction_seq)  \n",
    "    if (dist > anm_det_thr):\n",
    "        return true  # anomaly\n",
    "    else:\n",
    "        return false # normal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "colab_type": "code",
    "id": "sLBqHZLmomSD",
    "outputId": "375909cf-8a14-4e10-aa93-7d5d2fac440a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_76 (Conv1D)           (None, 16279, 32)         96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 8139, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 8138, 32)          2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 4069, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 130208)            0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 40)                5208360   \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1000)              41000     \n",
      "=================================================================\n",
      "Total params: 5,251,536\n",
      "Trainable params: 5,251,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' Generate Model for Predictor '''\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer #1\n",
    "# Computes 32 features using a 1D filter(kernel) of with w with ReLU activation. \n",
    "# Padding is added to preserve width.\n",
    "# Input Tensor Shape: [batch_size, w, 1] / batch_size = len(batch_sample)\n",
    "# Output Tensor Shape: [batch_size, w, num_filt_1] (num_filt_1 = 32 feature vectors)\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "\n",
    "# Pooling Layer #1\n",
    "# First max pooling layer with a filter of length 2 and stride of 2\n",
    "# Input Tensor Shape: [batch_size, w, num_filt_1]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1]\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "                    #  strides=pool_strides_1, \n",
    "                    #  padding='valid'))\n",
    "\n",
    "# Convolutional Layer #2\n",
    "# Computes 64 features using a 5x5 filter.\n",
    "# Padding is added to preserve width and height.\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, 32]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "# Max Pooling Layer #2\n",
    "# Second max pooling layer with a 2x2 filter and stride of 2\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "                    #  strides=pool_strides_2, \n",
    "                    #  padding='valid'\n",
    "          \n",
    "# Flatten tensor into a batch of vectors\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer (Output layer)\n",
    "# Densely connected layer with 1024 neurons\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 1024]\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu'))  \n",
    "\n",
    "# Dropout\n",
    "# Prevents overfitting in deep neural networks\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Output layer\n",
    "# Input Tensor Shape: [batch_size, 1024]\n",
    "# Output Tensor Shape: [batch_size, p_w]\n",
    "model.add(Dense(units=num_nrn_ol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "K76R-2HPajxI",
    "outputId": "b138835d-a0e7-4af7-a1fd-53b18446258a"
   },
   "outputs": [],
   "source": [
    "''' Compile our model'''\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "''' The paper talks about using stochastic gradient descent to optimize our parameters '''\n",
    "# sgd = keras.optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
    "# model.compile(optimizer='sgd', loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.1153\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1351\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1816\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0931\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0019\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0019\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0400\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0018\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0014\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0010\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0822e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.1298e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.4463e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.8043e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.0395e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.8193e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1860e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.4653e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.5320e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.6425e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.1333e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.8537e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.6582e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.3584e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.3704e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.2584e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0508\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0637\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.4083e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.6713e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.6944e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.1861e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.5405e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.1357e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.1111e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.8509e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5212e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.2154e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.9121e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5334e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4971e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.5108e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4678e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2769e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1190e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1768e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1233e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.0061e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.9583e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6920e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6002e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.6847e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7834e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6630e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0833e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1888e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0587e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7609e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6075e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5124e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.3988e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2255e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.4262e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2683e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9641e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.7382e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5940e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6293e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.6348e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6395e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.6175e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5836e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5088e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3841e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3021e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2775e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3902e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2843e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2449e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3726e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3128e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2414e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.1872e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0368\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0436\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.9136e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0680\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0537\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4.4741e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.5479e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.1747e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.5806e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0294e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.6741e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4317e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3924e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4364e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.4265e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.3293e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.1663e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.0986e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.9802e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.9003e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8494e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7944e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.7348e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6888e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.6133e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.5437e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5959e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5516e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5294e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5196e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4857e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4634e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4338e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3807e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3634e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4034e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3392e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2287e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2351e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2969e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3200e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2952e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1969e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1916e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2261e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1718e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1921e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1422e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1768e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1647e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1868e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1612e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1300e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0964e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1061e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1196e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1158e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1144e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1019e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0910e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1124e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 243.1348\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8198e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.9900e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8446e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5305e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3132e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3253e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.5471e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5435e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3991e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3549e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3080e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3117e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2364e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1951e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1551e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3042e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2113e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1598e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1609e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1692e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.1949e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1450e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1577e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0814e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1162e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1133e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1211e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1252e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2536\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2536\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2536\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2536\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2536\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2536\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2536\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2536\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2536\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2536\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2536\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2536\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2536\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2536\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2536\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2535\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2535\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2535\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2535\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2535\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2535\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2535\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2535\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2535\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2535\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2535\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2535\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2535\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2535\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6887\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7173\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6887\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.6887\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 7.6887\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.6886\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6885\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.6885\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.6884\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.6884\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.6883\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.6882\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.6881\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.6881\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6880\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.6879\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.6878\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6878\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.6877\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.6876\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.6875\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.6874\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.6873\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6872\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6871\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.6870\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.6870\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 7.6869\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.6868\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.6867\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1123\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1123\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1646\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1125\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1125\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1125\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1125\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1124\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1124\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1124\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1123\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1123\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1122\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1121\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1121\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1120\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1120\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1119\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1118\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1117\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1116\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1115\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1115\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1114\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1113\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1112\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1111\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1110\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1109\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1108\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.2302e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.2727e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7.4217e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.6023e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.8707e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3860e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.1577e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5.2466e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5357e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.8539e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.0622e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.1205e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.0640e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9247e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7556e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.4174e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.0270e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.5671e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4.1421e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.7554e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.4746e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3172e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.2850e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.3712e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.3124e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.2200e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.0409e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.7864e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5573e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.3218e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.0934e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.9274e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.8211e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7069e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6029e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4842e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4813e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5482e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5569e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5637e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6156e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.6411e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6033e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5928e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5415e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4696e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4592e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3759e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2597e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2841e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2804e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1800e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1818e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1910e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2381e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2355e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1864e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1162e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0569e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1029e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1405e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1064e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1223e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2003e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2307e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2036e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1662e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1480e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1235e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1035e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1271e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0779e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0667e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0527e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1053e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1140e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0557e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0904e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0828e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0969e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0931e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0096e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0631e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1163e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0991e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0875e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0544e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0177e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0221e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0567e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0844e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0705e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0708e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1096e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1013e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0664e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0827e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0793e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0260e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0097e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0467e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0467e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0697e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0820e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0793e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1223e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1638e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0964e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0666e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0713e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1314e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0943e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0165e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0406e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0196e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0270e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0443e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.8918e-05\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.4696e-05\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0742e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1184e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0413e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0570e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0614e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0873e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1016e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1204e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0872e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0446e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0377e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0603e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0806e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0159e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0467e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1020e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0544e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0487e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0632e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0677e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0887e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0857e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.8290e-05\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.7872e-05\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0367e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0676e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1000e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0430e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0309e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0382e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1167e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1031e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0205e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0633e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0729e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1133e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0640e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0420e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0384e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0499e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.0482e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0585e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0472e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0769e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1307e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1033e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0994e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1029e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1242e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0577e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0286e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0119e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.7878e-05\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0012e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0539e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0641e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.0484e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.0538e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.0293e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0194e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0461e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0868e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0257e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0479e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1094e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0760e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0511e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1053e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1035e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0409e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0678e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1058e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0971e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0583e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0707e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1258e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0797e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0732e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0443e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0018e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0347e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0962e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0527e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.8295e-05\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0674e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1080e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1205e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0890e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0062e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0353e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0781e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0864e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0382e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.9970e-05\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.8811e-05\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0655e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0486e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.9377e-05\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0676e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0604e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0428e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0467e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0706e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0860e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0825e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0931e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0767e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0925e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0993e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.0747e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0654e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0545e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0276e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0216e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0425e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0936e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0889e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0756e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0115e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.7467e-05\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0494e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0493e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.6448e-05\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.9467e-05\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0166e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0742e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1661e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1664e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1141e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0679e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0579e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1136e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1347e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1057e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0765e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0862e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0752e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0836e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0765e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0402e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0464e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0723e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0250e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0450e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0783e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0921e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0896e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0921e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0601e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0278e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0239e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0615e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0398e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0244e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0740e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0656e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0529e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0467e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0401e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0478e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0438e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0779e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0884e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0943e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0919e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0642e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0550e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0755e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0748e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0697e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0766e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0404e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0234e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0356e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0491e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0391e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0462e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0275e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8480e-05\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0281e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0672e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0595e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0445e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0319e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0526e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0622e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0689e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1052e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0952e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0625e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0990e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0645e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0136e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0340e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0436e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0673e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0490e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0505e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0596e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0472e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0461e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0603e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0227e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0016e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0435e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0534e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0472e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2551\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2551\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2551\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2551\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2551\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2551\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2551\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2551\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2551\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2551\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2551\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2551\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2551\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2551\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2551\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2551\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2551\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2551\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2551\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2551\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2551\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2550\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2550\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2550\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2550\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2550\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2550\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2550\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2550\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2550\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2904e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2346e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2018e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.2493e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2910e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2616e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.2433e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.2464e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.1728e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.1220e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.0715e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0682e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0747e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.9917e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.9851e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.9408e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.9203e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8864e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8491e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.8039e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7658e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7268e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6739e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6399e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5865e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4922e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4828e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4425e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3649e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3136e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2822e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2604e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2366e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2508e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2175e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1706e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1300e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1236e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0852e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1003e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1911e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2047e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1784e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1422e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1442e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1806e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1941e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1325e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1210e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1760e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1512e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0953e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0885e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0333e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0831e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0741e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0279e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0495e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0702e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0993e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0845e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0662e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0361e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1071e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1150e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0539e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0818e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1271e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1388e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0734e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0486e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0431e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0351e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0335e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0599e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0792e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0774e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1125e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1155e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0862e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0652e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0321e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0220e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0261e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0397e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0414e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0185e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0061e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0287e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0590e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0610e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0684e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0529e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0856e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0905e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0854e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1141e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1062e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0631e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0228e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0328e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0458e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0557e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0610e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0477e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0657e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1033e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0612e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0360e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0226e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0598e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0616e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0514e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0700e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0571e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0635e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0442e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0682e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0388e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0508e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0748e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0473e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0170e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0345e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0752e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0276e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0290e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0170e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0220e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0770e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1101e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1112e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0944e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1119e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1143e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1289e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0997e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0362e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0510e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0598e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0451e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0142e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0020e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0285e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0279e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0006e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.9834e-05\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0721e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0838e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0730e-04\n",
      "(1, 16280, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0867e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0748e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0934e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0811e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0659e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0192e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0279e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0768e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0692e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0413e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0397e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0669e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0523e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0392e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0140e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0210e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0855e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0761e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0567e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0872e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0451e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0320e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0427e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0685e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0855e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0931e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0549e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0337e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0698e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0567e-04\n"
     ]
    }
   ],
   "source": [
    "''' Training our model with multiple timeseries'''\n",
    "\n",
    "for i in range(len(reg_data.columns)):\n",
    "    sample = batch_sample[i].reshape((1,batch_sample.shape[1],batch_sample.shape[2]))\n",
    "    label = batch_label[i].reshape((batch_label.shape[1],batch_label.shape[2]))\n",
    "    \n",
    "    model.fit(sample, label, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "URqDB0oxhX_X",
    "outputId": "35e8073b-7b4e-4098-f5e7-0f000124a0ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 468ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00010728104098234326"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                 \"\"\"Testing with random interval(DeepAnT)\"\"\"\n",
    "# Set number of test sequences \n",
    "n_test_seq = 1\n",
    "\n",
    "# Split a univariate sequence into samples\n",
    "def generate_test_batch(raw_seq, n_test_seq):\n",
    "  # Sample a portion of the raw_seq randomly\n",
    "    ran_ix = random.randint(0,len(raw_seq) - n_test_seq * w - n_test_seq * p_w)\n",
    "    raw_test_seq = np.array(raw_seq[ran_ix:ran_ix + n_test_seq * w +  n_test_seq * p_w])\n",
    "    batch_test_seq, batch_test_label = list(), list()\n",
    "    ix = ran_ix\n",
    "    \n",
    "    for i in range(n_test_seq):\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = raw_seq[ix : ix+w],\n",
    "        seq_y = raw_seq[ix+w : ix+w+p_w]\n",
    "        ix = ix+w+p_w\n",
    "        batch_test_seq.append(seq_x)\n",
    "        batch_test_label.append(seq_y)\n",
    "        \n",
    "    return np.array(batch_test_seq), np.array(batch_test_label)\n",
    "\n",
    "batch_test_seq, batch_test_label = generate_test_batch(list(reg_data.ix[:,0]), n_test_seq)\n",
    "batch_test_seq = batch_test_seq.reshape((batch_test_seq.shape[0], w, n_features))\n",
    "batch_test_label = batch_test_label.reshape((batch_test_label.shape[0], p_w))\n",
    "\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "model.evaluate(x=batch_test_seq,\n",
    "               y=batch_test_label,\n",
    "               verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK0_Cq-Oh0tC"
   },
   "outputs": [],
   "source": [
    "# save our weights in order for faster loadtimes later\n",
    "model.save_weights(filename + '_weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2-oM2iL1gw4Q",
    "outputId": "a8ac362e-fccd-4d6c-f946-386a27620206"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 420ms/step\n",
      "[[-2.97329971e-04  5.90000345e-05  3.54966869e-05 -3.76878597e-06\n",
      "  -6.49434151e-05 -4.14592068e-05  1.62483193e-05 -1.31124747e-04\n",
      "  -5.98648039e-05  2.92583922e-04  1.33264984e-05 -1.07328044e-04\n",
      "  -1.06869556e-05  3.12147662e-04 -5.08029443e-05 -6.98478980e-05\n",
      "   2.64836854e-06 -4.98932131e-05  4.29476859e-06 -1.46173872e-04\n",
      "  -2.87043804e-07 -3.09201219e-04 -3.14091230e-05 -9.00205923e-05\n",
      "  -1.09654975e-04 -3.29752220e-05  1.86168385e-04  2.89551863e-05\n",
      "  -2.98403320e-05 -3.82809085e-05 -1.40304837e-06  2.17767374e-04\n",
      "  -6.36323239e-06  1.21307094e-05 -2.95112732e-05  3.14302801e-04\n",
      "   7.97357934e-05 -2.88375013e-04  1.74678571e-05 -2.11150327e-05\n",
      "   8.80656371e-05 -6.38978236e-07 -2.40728368e-05 -8.72436576e-05\n",
      "  -1.89415237e-04  1.76622794e-04  5.34946121e-05  6.89736407e-05\n",
      "  -1.92086853e-04  6.33331074e-05 -1.79015013e-04 -6.96335337e-05\n",
      "  -1.71493943e-04  1.00572594e-04  1.81944357e-04  1.04307146e-05\n",
      "  -1.49182961e-06  1.47744577e-04 -2.19223206e-04 -7.01599711e-05\n",
      "   1.97848422e-04 -3.87900363e-05 -3.16322607e-04 -2.23710340e-05\n",
      "  -7.87774698e-05  1.91159314e-04  9.84349754e-06 -1.77570866e-04\n",
      "  -2.27145487e-04 -2.64881586e-04  5.27421071e-05  4.07766165e-05\n",
      "  -2.92140350e-04  3.10868461e-04  2.99817417e-04  1.31413253e-04\n",
      "   2.86658469e-05  2.22371280e-04  1.41933124e-04  3.08565242e-04\n",
      "   1.46795443e-04 -6.33038653e-05 -3.75844975e-05  2.17959518e-04\n",
      "  -2.73521495e-04  6.73257236e-05 -4.41820266e-05 -1.39047515e-05\n",
      "  -1.08147098e-04  1.60509750e-04  3.53276700e-05 -1.26767685e-04\n",
      "   6.90363304e-05 -5.55144652e-07 -1.80289921e-04  1.39589742e-04\n",
      "   1.25247068e-04 -4.58289287e-06 -1.35354916e-04  1.50560481e-05\n",
      "  -3.00129650e-05 -6.16308753e-05  3.19479499e-04  7.75475055e-05\n",
      "  -1.84660850e-04 -1.02888094e-04 -7.58690949e-05  1.82607328e-05\n",
      "   1.82869626e-04  6.52591771e-05  9.50404137e-06  2.48859578e-06\n",
      "   1.80986637e-04 -1.72732151e-04 -4.64788827e-05  9.08993316e-05\n",
      "   5.01311442e-05  1.16731098e-06  3.12188640e-04 -9.11869793e-05\n",
      "  -9.63780258e-05 -7.74783257e-06 -1.62773591e-04  4.65694393e-05\n",
      "   6.09026065e-05 -3.54928416e-05 -1.24797574e-04 -2.16216373e-04\n",
      "   7.05607308e-05  1.76519010e-04  3.87932450e-05 -9.75842850e-05\n",
      "   2.77250547e-05  4.83957920e-05 -1.16722687e-04 -8.89173170e-05\n",
      "  -5.05336466e-05 -1.32170520e-04  8.02149079e-05  1.41453202e-05\n",
      "   5.07213408e-05  1.50667649e-04  2.82679714e-04 -7.93920772e-05\n",
      "  -1.63922989e-04 -1.52004850e-05  2.09065271e-04  1.78859351e-04\n",
      "   6.63800893e-06 -1.78388917e-04  2.82594556e-05  9.09908049e-05\n",
      "  -3.24960820e-05 -3.02511704e-04 -3.91123613e-05 -6.36550030e-05\n",
      "   3.83902516e-05  5.42010639e-05  1.02622958e-04  9.29908638e-05\n",
      "  -2.18960180e-04 -7.62740310e-05  2.29281504e-05 -1.07262407e-04\n",
      "   2.81396759e-04 -1.82678516e-04  1.42351782e-04 -6.04144589e-05\n",
      "  -2.76087303e-06  2.25699885e-04  1.77108814e-04  1.90447681e-04\n",
      "   9.28778318e-05  1.73572596e-04 -4.20403521e-05  3.52040879e-05\n",
      "  -3.55388474e-05 -5.19017267e-05 -1.78672432e-04  1.35222261e-04\n",
      "  -1.21002813e-07 -3.58168472e-05 -1.14073555e-06 -1.30673798e-04\n",
      "   3.37369856e-05  1.49883956e-04  1.07584972e-04  6.07157199e-05\n",
      "  -1.49359927e-04  5.47322925e-05 -9.38711455e-05 -7.74300788e-05\n",
      "   5.49000652e-05  1.52424109e-04  2.32517254e-04 -6.67877757e-05\n",
      "   1.88696475e-04 -1.35777183e-04 -2.04812546e-04  7.86949677e-05\n",
      "  -3.31735500e-05  4.50263440e-04  1.25889826e-04 -1.55415240e-04\n",
      "   1.23514255e-05  2.20357295e-04 -7.54884240e-06  1.76439571e-04\n",
      "   7.22843979e-05  1.76600297e-04 -2.30346122e-05  2.22114722e-05\n",
      "   3.78655590e-04 -3.20591789e-05  2.82319117e-04 -3.66975401e-05\n",
      "  -1.51032757e-04 -1.39614465e-04  7.85732773e-05  1.37259252e-04\n",
      "  -9.52162591e-05  3.04692046e-04  1.02533559e-05  2.64476286e-04\n",
      "  -2.19053371e-04  7.12366018e-05 -9.52484188e-05  2.15964537e-04\n",
      "  -2.33694009e-05 -5.20144713e-05  1.42158533e-04  4.42055425e-05\n",
      "  -5.74846526e-05  7.59283212e-05  6.27180270e-05 -9.12925461e-05\n",
      "  -9.92622008e-05  9.90199042e-05 -6.01756401e-05 -1.47675630e-04\n",
      "  -2.21968148e-04 -6.30019713e-05 -1.75082256e-04 -4.95899440e-06\n",
      "  -6.04817142e-05 -1.86051271e-04  5.85416929e-05 -2.00136146e-05\n",
      "  -8.73913523e-05 -7.62004493e-05  5.26380609e-05 -5.77907667e-05\n",
      "   5.65485971e-06 -1.13268325e-05 -1.46341059e-04  1.62314449e-04\n",
      "   1.35822920e-05  1.56908172e-05  2.04952667e-05  1.00521407e-04\n",
      "  -6.04860870e-05  1.80448056e-04 -1.62941680e-04 -8.82756067e-05\n",
      "  -3.50208938e-05 -1.30114786e-04  8.99833394e-05 -3.62579849e-05\n",
      "   6.02325381e-05 -4.55125773e-05  4.59914008e-06 -6.97014111e-05\n",
      "   6.68562352e-05 -3.59219521e-05 -1.48503401e-04 -9.95399023e-05\n",
      "   2.84513408e-05  8.67769922e-05 -4.81648603e-05  8.77602361e-05\n",
      "  -2.84599810e-06 -4.49215659e-05 -1.39184449e-05 -1.34644157e-04\n",
      "  -9.14454213e-05 -2.48167780e-05  1.79109629e-05 -1.49295345e-04\n",
      "   2.44702460e-06 -1.29587352e-05 -2.96008366e-05  8.83489483e-05\n",
      "   6.05153982e-05 -8.73865429e-05  2.69061100e-04  2.24941759e-05\n",
      "  -8.99661973e-05  4.48211358e-06 -2.63679940e-05 -5.97280923e-05\n",
      "   1.72430911e-04  5.96500977e-05  7.33602938e-05  9.08582806e-05\n",
      "   1.74100787e-04 -8.44882670e-05  1.06158659e-04 -2.04704411e-04\n",
      "  -9.23690095e-05  1.62280849e-05  1.14090813e-04  9.00539526e-05\n",
      "  -5.05476564e-05  3.78470431e-05 -2.47507778e-05 -3.89634806e-06\n",
      "  -1.71295222e-04  1.39661541e-04 -1.52838300e-04  4.48071107e-04\n",
      "   8.41092842e-05  1.98059090e-04 -5.19490277e-06  2.46493528e-06\n",
      "   1.43625643e-04  3.41972554e-05 -6.06754002e-05  4.70243176e-05\n",
      "   1.35885464e-04 -9.10872404e-05 -2.22260387e-05 -6.35841134e-05\n",
      "  -1.38419055e-04 -6.00853709e-05  2.85117683e-04 -4.34312824e-07\n",
      "   1.26544488e-04 -1.36778501e-04  1.37413590e-04 -2.23519601e-06\n",
      "  -1.68350147e-04  4.35659385e-05  3.35694640e-05 -4.58568829e-05\n",
      "  -8.36450126e-05 -2.26003467e-05 -1.33928479e-05  1.31170309e-04\n",
      "   1.99441536e-04 -5.10306563e-06  1.32224275e-04  5.01792019e-05\n",
      "   7.85045922e-05  4.28012572e-06  2.26912089e-05  3.41341365e-05\n",
      "   6.04707166e-05  1.30343367e-04  5.38376225e-05  1.60316995e-06\n",
      "  -2.37083179e-04  1.55563001e-04  9.47876833e-05  1.85847661e-04\n",
      "  -1.45221245e-04 -8.35474566e-05 -2.87505158e-04  4.28264902e-05\n",
      "   7.05834973e-05  7.81666313e-05 -2.20910770e-05 -2.68725154e-04\n",
      "   1.81761206e-04  4.83897966e-05  2.75180391e-05  4.89829981e-05\n",
      "   2.95068370e-04 -1.90973660e-04  1.51137618e-04 -1.79652707e-05\n",
      "  -7.04340346e-05 -6.50565926e-05 -2.27360288e-05  1.37998504e-04\n",
      "  -1.08151435e-05 -1.37296011e-04  1.41997210e-04  1.66281025e-05\n",
      "  -1.11482463e-04  7.79664333e-05 -3.52311035e-05 -1.36041286e-04\n",
      "   1.01321260e-04  2.63362774e-04  1.90702121e-06  1.50922599e-04\n",
      "  -2.33179395e-04  1.75130714e-04  1.01026206e-04  3.06277914e-04\n",
      "   2.99249892e-04  1.76127418e-04 -2.09044185e-04 -9.17580692e-05\n",
      "   2.85747607e-04 -1.73840992e-04  7.59943068e-05 -1.41594181e-04\n",
      "  -6.82150130e-05 -2.00238283e-04 -5.44668364e-06 -2.84506881e-04\n",
      "  -3.82237195e-05  7.23722333e-05 -1.29387481e-04  1.57144677e-06\n",
      "  -4.96768334e-05  6.22675943e-05  4.69424558e-05  2.77838786e-04\n",
      "   1.26523242e-04  1.17887903e-05  2.98192972e-05 -1.60492898e-04\n",
      "   1.49337531e-04 -4.98000227e-05  4.16295370e-06  1.70100160e-04\n",
      "   1.77849797e-04 -5.93896148e-05 -1.91257277e-05  8.68630814e-05\n",
      "  -1.11071713e-05 -1.44466612e-05 -1.03320861e-04  5.97827093e-05\n",
      "   7.84842268e-05  8.36737890e-05  1.96187102e-04 -4.43674253e-05\n",
      "  -7.75776425e-06  8.32060541e-05 -2.34577165e-05  6.91534005e-05\n",
      "   1.48043036e-04 -6.71900634e-05 -2.71663012e-05 -9.06256828e-05\n",
      "  -1.82945485e-04 -2.34449763e-05 -1.98529277e-04 -1.32511617e-04\n",
      "   5.81428503e-05 -1.80875169e-04 -6.59812358e-05 -9.96274466e-05\n",
      "  -1.51806162e-05 -1.86650606e-04  9.90668050e-05  5.02237781e-05\n",
      "  -1.95524190e-05  5.82505199e-05 -2.82566180e-06 -1.76478192e-04\n",
      "   2.64138544e-05  1.14219802e-06 -3.74033662e-05  1.87814498e-04\n",
      "  -2.00507377e-04  1.63544173e-05 -2.70288525e-04 -5.05369717e-05\n",
      "  -3.88013359e-05 -1.76562186e-04 -8.38660344e-05 -3.56390956e-06\n",
      "   3.15999845e-04 -5.96142163e-05 -8.05445088e-05 -1.98247100e-04\n",
      "  -1.46182239e-04 -9.76598967e-05  8.81339001e-05 -4.50338121e-04\n",
      "  -4.20383003e-06  1.79100651e-04 -9.02830434e-05 -1.80292409e-06\n",
      "  -1.35904498e-04 -1.62150594e-04  9.51510301e-05 -6.06964313e-05\n",
      "   6.77445787e-05  6.11110590e-05 -1.41645985e-04  1.08792301e-06\n",
      "  -1.25190854e-06  2.88669435e-05 -2.20357848e-04 -9.98763426e-06\n",
      "  -6.01581851e-05 -1.06408435e-04  7.55969959e-05  1.22953381e-04\n",
      "   1.94417255e-04 -1.47655228e-05  4.55206246e-05 -1.38707677e-04\n",
      "   1.46012462e-05  1.63918412e-05 -5.66770941e-05 -3.42544154e-05\n",
      "  -9.92631176e-05  1.73899403e-04 -1.85709025e-04  5.05124262e-05\n",
      "  -3.61348248e-05  1.22954356e-04 -8.60632790e-05 -1.79984781e-05\n",
      "  -9.24445048e-05  7.94010703e-05  1.94860913e-05  4.50881838e-04\n",
      "  -2.07341145e-05 -5.78917716e-05 -7.19908930e-05  2.15837877e-04\n",
      "   9.99788681e-05  1.32339526e-04  9.30499737e-05 -6.88221335e-05\n",
      "   1.89992046e-04  2.17949404e-04  9.13828480e-05  1.32296380e-04\n",
      "  -3.50206683e-05 -1.46311068e-05 -2.66638759e-04 -5.88270959e-05\n",
      "  -3.85749474e-04  7.97714019e-05  4.61548188e-06 -1.12802954e-05\n",
      "  -1.88050821e-04 -9.18993246e-05 -4.43369849e-04 -5.79894695e-05\n",
      "  -1.26172730e-04 -1.41091332e-05  5.87304166e-05  9.68252498e-05\n",
      "  -9.96796880e-05  1.68798761e-06 -2.21054768e-04 -4.47388447e-04\n",
      "  -6.02624641e-06 -1.48168561e-04 -1.97793444e-04 -1.03498503e-04\n",
      "   6.52986637e-06  5.65008777e-05  1.69721141e-04 -1.36855655e-04\n",
      "  -9.16310019e-05 -1.79799550e-04  2.55489431e-06 -4.52174398e-04\n",
      "   3.93924929e-05  6.10043244e-05  1.77883689e-04  2.69712968e-04\n",
      "  -4.76987698e-05  1.50206615e-04  1.57763134e-04 -1.04634964e-05\n",
      "  -5.25324940e-05 -4.55844856e-04  7.26351718e-05  1.89240396e-04\n",
      "  -2.64671398e-04 -2.81165878e-04 -1.79490889e-05 -9.91210545e-05\n",
      "   1.04314422e-05 -2.72167643e-04 -5.54646285e-05  3.45752633e-05\n",
      "  -1.56617170e-05 -8.11399223e-05  8.88739305e-05 -1.71225736e-04\n",
      "   1.99305177e-05  5.61325614e-05 -4.20757046e-04  1.51676271e-04\n",
      "  -3.07667360e-05 -1.98565496e-04 -2.75813363e-04  1.92044477e-04\n",
      "  -2.01699077e-04 -2.85298709e-04 -1.26720915e-04  4.16140138e-05\n",
      "  -5.80212800e-05  2.81729706e-04  8.89913063e-05  3.64866792e-05\n",
      "  -2.86175928e-05  8.52259618e-05  2.34918989e-04 -7.69460603e-05\n",
      "   1.73400214e-04  9.15422788e-05 -1.86883350e-04 -3.83688784e-05\n",
      "  -4.87821853e-05 -4.66348574e-05  6.58502904e-05 -2.96762992e-05\n",
      "   1.50977954e-04 -1.23215956e-04  2.01316143e-04 -7.38332164e-05\n",
      "   2.06562807e-04 -1.44804617e-05  1.62638491e-04  8.98212238e-05\n",
      "  -8.73600366e-05  1.22776881e-04 -8.33249433e-05  1.48410152e-04\n",
      "  -7.68653772e-05 -9.86193918e-05  1.27804218e-04  1.79297989e-04\n",
      "  -1.33056892e-05 -1.27221443e-04  1.75824316e-04  2.34405423e-04\n",
      "  -7.34302448e-05  2.25659867e-04  5.85636335e-05 -2.33791739e-04\n",
      "  -9.26961293e-05  6.15514437e-05 -1.55734509e-04 -5.51627891e-05\n",
      "   2.98027589e-05 -1.77992508e-04 -1.48687221e-04 -2.66603485e-04\n",
      "  -8.67813578e-05  3.19452200e-04  1.79149356e-04 -5.90435302e-05\n",
      "  -6.93188122e-05  3.67243338e-05 -5.52572528e-05 -2.06087134e-05\n",
      "  -1.35228474e-04  6.04772831e-05 -9.57685988e-05 -1.58944276e-05\n",
      "   1.80953793e-06 -5.89072952e-05 -1.26574290e-04  1.08471613e-04\n",
      "   2.17799388e-05 -2.21007038e-04 -9.98057658e-06 -1.27923515e-04\n",
      "   1.22718833e-04  5.10977879e-05  1.46847160e-05  1.80369476e-04\n",
      "  -6.51467926e-05  1.25073042e-04  1.76590125e-04  3.49335387e-05\n",
      "  -1.90807914e-05 -6.53136376e-05 -3.84377963e-05 -7.11898465e-05\n",
      "  -1.26310057e-04  2.23861571e-04  1.45520680e-04  1.70353451e-06\n",
      "   2.26704200e-04 -1.68699262e-04 -5.25149953e-05 -1.23808233e-04\n",
      "   5.63898539e-05  1.07030457e-04  1.83323136e-05  4.76571295e-05\n",
      "  -3.64329971e-05 -1.01446167e-04  5.12311963e-05 -1.22395082e-04\n",
      "  -9.81347548e-05  2.69207289e-04 -8.26396208e-05 -1.41974917e-04\n",
      "   1.43204379e-05  3.71080168e-05  7.08272637e-05 -1.73134758e-04\n",
      "  -3.00095126e-05  2.04596581e-04 -2.78662628e-05 -2.21424270e-04\n",
      "  -1.41187455e-04 -8.41044530e-05  7.53916320e-05 -1.32150308e-05\n",
      "   1.22534519e-04 -1.77606140e-04 -5.26674885e-05 -5.14452004e-05\n",
      "   6.18182748e-05  4.49489627e-04  5.30792713e-05  1.92289488e-04\n",
      "   7.66830999e-06  5.55081169e-05 -4.51599335e-05 -6.13377051e-05\n",
      "  -4.65328958e-06 -2.64091534e-04 -8.59017964e-05  1.31585650e-04\n",
      "   2.83626054e-04  1.53788395e-04 -7.31112959e-06 -1.39521988e-04\n",
      "  -8.57943887e-05  2.71708959e-05  2.36690801e-04 -7.71630876e-05\n",
      "   1.57329341e-05  3.63626459e-05 -3.35793884e-05 -2.37723871e-05\n",
      "  -2.67114010e-05 -1.72726373e-04 -9.35469870e-06  1.52940192e-04\n",
      "  -1.38209434e-04  4.35269576e-05  1.85545359e-05  5.33495040e-06\n",
      "   5.22332266e-05 -8.79210056e-05 -8.28123084e-05 -8.15980093e-05\n",
      "   1.85162164e-04 -8.80756634e-05 -1.74930916e-04  1.27458130e-04\n",
      "   1.08460954e-04 -1.96422363e-04 -4.91209503e-05 -5.51313169e-05\n",
      "   5.63563844e-05  5.70391603e-05 -1.05018837e-04  1.88777631e-06\n",
      "   8.66682603e-05 -1.35445298e-05 -4.30056134e-05  9.60819889e-05\n",
      "  -1.67222446e-04  5.45298099e-05 -1.35483715e-04 -1.01647020e-04\n",
      "  -1.96278270e-05  1.71410924e-04  3.91678441e-05 -6.06738649e-05\n",
      "  -5.06636134e-05 -8.79805375e-05 -2.78621330e-04 -3.81610080e-05\n",
      "   6.05445821e-05  1.73317589e-04 -8.91983727e-05  1.51444314e-04\n",
      "   1.43110112e-04 -7.39203679e-05 -3.71978676e-05 -2.88574840e-04\n",
      "   1.07038948e-04 -1.35152193e-04 -4.35092807e-05  2.99216714e-04\n",
      "   8.91974196e-06 -1.90899300e-06 -1.34845366e-04  4.44156540e-05\n",
      "  -1.29500535e-04  1.75653724e-04  1.93615997e-04 -1.14605355e-05\n",
      "  -1.80231349e-04  2.18852219e-04  4.20081633e-05 -8.88517025e-05\n",
      "  -1.16336676e-04 -8.64820904e-05  1.29746739e-04 -1.68879415e-04\n",
      "  -1.91355721e-04  2.88656709e-04  2.60871311e-05  1.42290228e-04\n",
      "  -8.92483440e-05 -1.76909671e-04  4.86269346e-06 -1.00109246e-05\n",
      "  -6.51225928e-05  3.49946349e-04 -4.09840577e-05 -5.53631253e-06\n",
      "   9.53282433e-05 -1.74962828e-04 -6.44974934e-05 -4.83202093e-05\n",
      "  -2.94921163e-04 -5.21810434e-05 -1.99454065e-04  2.94801081e-04\n",
      "  -1.70525469e-04 -1.78468996e-04  5.62802343e-05  6.72090464e-05\n",
      "  -3.25649453e-05 -3.83258703e-06  7.79633410e-06 -5.34000937e-05\n",
      "  -1.76928705e-04  8.43572052e-05 -4.22130870e-05  1.00715581e-04\n",
      "   2.95589038e-04  2.93031298e-05  1.96555993e-04 -1.35261434e-04\n",
      "   8.78630308e-05 -7.95003871e-06 -7.31477194e-05 -8.36083636e-05\n",
      "   2.85608141e-04 -7.31568653e-05  1.85051322e-04  9.16751233e-05\n",
      "  -5.12574261e-05 -5.30798752e-05  2.31729064e-05  1.81301039e-05\n",
      "   1.90341379e-05 -6.07523289e-05 -5.54275975e-05  7.79910697e-05\n",
      "   3.54372460e-05 -2.93714256e-04 -8.46182302e-05 -8.82050444e-05\n",
      "   6.52767922e-05 -2.16633460e-04  8.15569874e-05 -1.57642062e-05\n",
      "  -8.79682120e-05 -5.52941710e-05  6.35845936e-07  7.86048113e-05\n",
      "   3.11712851e-04 -7.30702595e-07  8.08795521e-05 -3.30766707e-05\n",
      "   7.35032881e-05 -1.98504247e-04  1.59445350e-04  2.87192321e-04\n",
      "   8.61394219e-05 -1.76291564e-04  3.03202978e-06  2.20674381e-04\n",
      "   1.50695938e-04  3.82394137e-06 -1.89850980e-04  6.01670945e-05\n",
      "   1.88335835e-05  3.15626239e-05  1.06996958e-05 -4.89310187e-05\n",
      "  -5.23007184e-05 -8.99680308e-05 -7.23475532e-05  7.30293541e-05\n",
      "  -1.51960194e-04  1.94388427e-04  1.76215588e-04 -2.35148873e-05\n",
      "  -2.28427743e-05  1.95626635e-05 -1.80049014e-04  6.99839366e-05\n",
      "  -3.05120375e-05 -9.08523143e-05  4.57271148e-04  6.17136830e-05\n",
      "  -1.11615111e-04 -6.92020985e-05 -3.10540723e-04 -1.74217625e-04\n",
      "   1.52274020e-04  1.42410892e-04 -6.46942572e-05 -1.26839077e-04\n",
      "   1.26497544e-04 -9.23086991e-05  3.80642196e-05  3.65210435e-05\n",
      "  -8.44663446e-05  2.61930218e-05 -2.08346428e-05 -8.41125948e-05\n",
      "  -3.19940969e-04 -2.33544764e-04 -1.76217611e-04 -5.81364657e-05\n",
      "  -1.08132059e-04  4.30824002e-06  2.12373561e-05 -6.49998110e-05\n",
      "  -6.68077264e-05  4.59549119e-05 -1.95834305e-04 -2.81307468e-04\n",
      "  -1.77152877e-04  1.43058802e-04 -1.28850428e-04 -2.28158897e-05\n",
      "   1.46749255e-04 -7.39040552e-05  1.76469635e-04  1.87753496e-04\n",
      "   3.19527171e-04  4.87742582e-05 -3.33033895e-05  7.64022261e-05\n",
      "  -6.01484971e-05 -4.52905486e-04 -2.81556830e-04  5.55732695e-05\n",
      "  -2.34795676e-04 -3.95808856e-05 -3.72882205e-05  1.48726307e-04\n",
      "  -8.41194633e-05  2.14553293e-04  3.20973340e-05 -1.26376297e-04\n",
      "  -2.37821041e-05 -6.50264483e-05 -1.80409814e-04  2.40201131e-04\n",
      "   1.73908338e-05  7.69599865e-05  5.64229049e-06  2.94348894e-04\n",
      "   1.69816238e-04  2.88600131e-05  1.37108727e-05 -1.01249541e-04\n",
      "  -1.74834800e-04 -2.27065189e-04 -4.47878483e-05  8.19022753e-05\n",
      "   2.71767960e-04  4.45160185e-05 -9.12028991e-05  1.59844480e-04\n",
      "  -2.67234020e-04  6.74278781e-05 -3.21605512e-05 -7.53482891e-05\n",
      "  -3.25757021e-04 -1.54756970e-04 -3.88563378e-04 -8.62175875e-05\n",
      "   4.43801619e-05 -5.31342375e-05  3.52553179e-05 -2.90937518e-04\n",
      "   6.03712142e-05 -1.26912943e-04  1.79263836e-04  6.30861905e-08]]\n",
      "[-1.20479838e-07 -8.70823309e-08  3.37160009e-08  1.21258999e-07\n",
      "  8.76850241e-08 -3.38937684e-08 -1.22041626e-07 -8.82907532e-08\n",
      "  3.40719745e-08  1.22827749e-07  8.88995450e-08 -3.42506278e-08\n",
      " -1.23617401e-07 -8.95114277e-08  3.44297310e-08  1.24410612e-07\n",
      "  9.01264254e-08 -3.46092910e-08 -1.25207416e-07 -9.07445674e-08\n",
      "  3.47893128e-08  1.26007844e-07  9.13658793e-08 -3.49698007e-08\n",
      " -1.26811931e-07 -9.19903905e-08  3.51507603e-08  1.27619707e-07\n",
      "  9.26181278e-08 -3.53321969e-08 -1.28431208e-07 -9.32491190e-08\n",
      "  3.55141170e-08  1.29246467e-07  9.38833931e-08 -3.56965259e-08\n",
      " -1.30065517e-07 -9.45209783e-08  3.58794257e-08  1.30888393e-07\n",
      "  9.51619045e-08 -3.60628261e-08 -1.31715129e-07 -9.58061984e-08\n",
      "  3.62467302e-08  1.32545762e-07  9.64538922e-08 -3.64311458e-08\n",
      " -1.33380324e-07 -9.71050170e-08  3.66160751e-08  1.34218853e-07\n",
      "  9.77595975e-08 -3.68015259e-08 -1.35061383e-07 -9.84176691e-08\n",
      "  3.69875038e-08  1.35907951e-07  9.90792605e-08 -3.71740131e-08\n",
      " -1.36758595e-07 -9.97444014e-08  3.73610627e-08  1.37613351e-07\n",
      "  1.00413126e-07 -3.75486559e-08 -1.38472256e-07 -1.01085463e-07\n",
      "  3.77367983e-08  1.39335347e-07  1.01761446e-07 -3.79254969e-08\n",
      " -1.40202662e-07 -1.02441106e-07  3.81147569e-08  1.41074240e-07\n",
      "  1.03124477e-07 -3.83045837e-08 -1.41950120e-07 -1.03811590e-07\n",
      "  3.84949855e-08  1.42830342e-07  1.04502480e-07 -3.86859647e-08\n",
      " -1.43714942e-07 -1.05197179e-07  3.88775325e-08  1.44603965e-07\n",
      "  1.05895722e-07 -3.90696900e-08 -1.45497446e-07 -1.06598143e-07\n",
      "  3.92624471e-08  1.46395427e-07  1.07304475e-07 -3.94558077e-08\n",
      " -1.47297951e-07 -1.08014754e-07  3.96497804e-08  1.48205059e-07\n",
      "  1.08729015e-07 -3.98443689e-08 -1.49116791e-07 -1.09447293e-07\n",
      "  4.00395817e-08  1.50033188e-07  1.10169627e-07 -4.02354229e-08\n",
      " -1.50954296e-07 -1.10896049e-07  4.04319016e-08  1.51880157e-07\n",
      "  1.11626598e-07 -4.06290234e-08 -2.06479561e-07  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Predict Future Timeseries \"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "\n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('ch_3_noanom_weights.h5')\n",
    "          \n",
    "    \n",
    "raw_seq = list(reg_data.ix[:,0])\n",
    "endix = len(raw_seq) - w - p_w\n",
    "input_seq = np.array(raw_seq[endix:endix+w])\n",
    "target_seq = np.array(raw_seq[endix+w:endix+w+p_w]) \n",
    "input_seq = input_seq.reshape((1, w, n_features))\n",
    "\n",
    "# Predict the next time stampes of the sampled sequence\n",
    "predicted_seq = model.predict(input_seq, verbose=1\n",
    "                              \n",
    "# Calculate relative error between target sequence and prediction sequence\n",
    "pred_error = sum(tar_seq-pre_seq)/(len(tar_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "664VO9gMmmFE",
    "outputId": "0f8b7983-5c1c-4b94-d898-865d8f0fc0fd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7200x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Visualization of predicted time series'''\n",
    "\n",
    "in_seq = reg_data.ix[:,i][endix:endix+w]\n",
    "tar_seq = reg_data.ix[:,i][endix+w:endix+w+p_w]\n",
    "predicted_seq = predicted_seq.reshape((p_w))\n",
    "\n",
    "d = {'time': reg_data.ix[:,i][endix+w:endix+w+p_w], 'values': predicted_seq}\n",
    "df_pre = pd.DataFrame(data=d)\n",
    "pre_seq = df_pre['values']\n",
    "\n",
    "plt.plot(in_seq)\n",
    "plt.plot(tar_seq)\n",
    "plt.plot(tar_seq)\n",
    "\n",
    "\n",
    "plt.ylim(top = 0.1)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "plt.title('Channel 27 Prediction')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('time')\n",
    "plt.legend(['input_seq', 'target_sequence', 'pre_seq'], loc='upper right')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([endix,endix+w+p_w])\n",
    "fig_predict = plt.figure(figsize=(100,10))\n",
    "fig_predict.savefig('predicted_sequence.png')\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda6f2bec422dd747988837f1b049720b89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
