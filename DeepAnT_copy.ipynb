{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60oNtF4FWakJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling1D, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9A1LKB0GwtQH"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCvn51nkpuah"
   },
   "outputs": [],
   "source": [
    "              \"\"\"Hyperparameters\"\"\"\n",
    "w = 17280-500                 # History window (number of time stamps taken into account) \n",
    "                         # i.e., filter(kernel) size       \n",
    "p_w = 500                # Prediction window (number of time stampes required to be \n",
    "                         # predicted)\n",
    "n_features = 1           # Univariate time series\n",
    "\n",
    "kernel_size = 2          # Size of filter in conv layers\n",
    "num_filt_1 = 32          # Number of filters in first conv layer\n",
    "num_filt_2 = 32          # Number of filters in second conv layer\n",
    "num_nrn_dl = 40          # Number of neurons in dense layer\n",
    "num_nrn_ol = p_w        # Number of neurons in output layer\n",
    "\n",
    "conv_strides = 1\n",
    "pool_size_1 = 2          # Length of window of pooling layer 1\n",
    "pool_size_2 = 2          # Length of window of pooling layer 2\n",
    "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
    "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
    "\n",
    "epochs = 30\n",
    "dropout_rate = 0.5       # Dropout rate in the fully connected layer\n",
    "learning_rate = 2e-5  \n",
    "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "aKYzBd94KZFu",
    "outputId": "52cfaed6-92e1-42ab-8ce8-9e4af7cf69b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdf_helper import *\n",
    "from stat_helper import *\n",
    "from data_cleaning import *\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/datch_3.csv').drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "df_test = pd.read_csv('data/datch_3.csv', nrows=100)\n",
    "\n",
    "float_cols = [c for i, c in enumerate(df_test.columns) if i != 0]\n",
    "float64_cols = {c: np.float64 for c in float_cols}\n",
    "\n",
    "df = pd.read_csv('data/datch_3.csv', engine='c', dtype=float64_cols).drop(['Unnamed: 0'], axis = 1)\n",
    "df = df.replace(np.NAN, 0.0)\n",
    "\n",
    "zero_outliers = df.loc[:, (df == 0.0).all(axis=0)]\n",
    "reg_data = df.loc[:,(df != 0.0).any(axis=0)]\n",
    "\n",
    "#df = reduce_dataset_size(df, cluster_size = 50)\n",
    "df = smooth_values(df)\n",
    "scaler = RobustScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17280\n"
     ]
    }
   ],
   "source": [
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQsOxuDCIGpQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data preprocessing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + w\n",
    "        out_end_ix = end_ix + p_w\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17280, 27)\n",
      "(27, 1, 16780)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n",
      "C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# # define input sequence\n",
    "# for col in reg_data.columns:\n",
    "#     sampl, labl = split_sequence(list(reg_data[col]))\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "batch_sampl, batch_labl = split_sequence(list(reg_data.ix[:,0]))\n",
    "samples.append(batch_sampl)\n",
    "labels.append(batch_labl)\n",
    "\n",
    "print(reg_data.shape)\n",
    "\n",
    "for i in range(1, len(reg_data.columns)):\n",
    "    batch_sampl, batch_labl = split_sequence(list(reg_data.ix[:,i]))\n",
    "    samples.append(batch_sampl)\n",
    "    labels.append(batch_labl)\n",
    "    \n",
    "batch_sample = np.array(samples)\n",
    "batch_label = np.array(labels)\n",
    "    \n",
    "print(batch_sample.shape)\n",
    "\n",
    "# summarize the data\n",
    "# for i in range(5):\n",
    "#     print(X[i], Y[i])\n",
    "  \n",
    "# 2. reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "\n",
    "# need to convert batch into 3D tensor of the form [batch_size, input_seq_len, n_features]\n",
    "batch_sample = batch_sample.reshape((batch_sample.shape[0], batch_sample.shape[2], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 1, 500)\n",
      "(27, 16780, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_label = batch_label.reshape((batch_label.shape[0],batch_label.shape[1],batch_label.shape[2]))\n",
    "print(batch_label.shape)\n",
    "print(batch_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "colab_type": "code",
    "id": "sLBqHZLmomSD",
    "outputId": "375909cf-8a14-4e10-aa93-7d5d2fac440a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16779, 32)         96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 8389, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 8388, 32)          2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 4194, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 134208)            0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 40)                5368360   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               20500     \n",
      "=================================================================\n",
      "Total params: 5,391,036\n",
      "Trainable params: 5,391,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "              \"\"\"Generate model for predictor\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer #1\n",
    "# Computes 32 features using a 1D filter(kernel) of with w with ReLU activation. \n",
    "# Padding is added to preserve width.\n",
    "# Input Tensor Shape: [batch_size, w, 1] / batch_size = len(batch_sample)\n",
    "# Output Tensor Shape: [batch_size, w, num_filt_1] (num_filt_1 = 32 feature vectors)\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "\n",
    "# Pooling Layer #1\n",
    "# First max pooling layer with a filter of length 2 and stride of 2\n",
    "# Input Tensor Shape: [batch_size, w, num_filt_1]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1]\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "                    #  strides=pool_strides_1, \n",
    "                    #  padding='valid'))\n",
    "\n",
    "# Convolutional Layer #2\n",
    "# Computes 64 features using a 5x5 filter.\n",
    "# Padding is added to preserve width and height.\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, 32]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "# Max Pooling Layer #2\n",
    "# Second max pooling layer with a 2x2 filter and stride of 2\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "                    #  strides=pool_strides_2, \n",
    "                    #  padding='valid'\n",
    "          \n",
    "# Flatten tensor into a batch of vectors\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer (Output layer)\n",
    "# Densely connected layer with 1024 neurons\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 1024]\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu'))  \n",
    "\n",
    "# Dropout\n",
    "# Prevents overfitting in deep neural networks\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Output layer\n",
    "# Input Tensor Shape: [batch_size, 1024]\n",
    "# Output Tensor Shape: [batch_size, p_w]\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Summarize model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "K76R-2HPajxI",
    "outputId": "b138835d-a0e7-4af7-a1fd-53b18446258a"
   },
   "outputs": [],
   "source": [
    "                 '''configure model'''\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_absolute_error')\n",
    "\n",
    "# sgd = keras.optimizers.SGD(lr=learning_rate, \n",
    "#                          decay=1e-6, \n",
    "#                          momentum=0.9, \n",
    "#                          nesterov=True)\n",
    "# model.compile(optimizer='sgd', \n",
    "#               loss='mean_absolute_error', \n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MO8EMSBaMZ8K",
    "outputId": "7c033331-7d5e-473c-ac81-5c7971db6fa4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "model_fit = model.fit(batch_sample,\n",
    "                      batch_label,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.1359\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1035\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0660\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0310\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0021\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0380\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0290\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0020\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0019\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0015\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.3621e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.0696e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3473e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.0617e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.8230e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.7850e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.2730e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.7756e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.5169e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3218e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.0642e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.9356e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4.6477e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3247e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.8715e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.6806e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0309\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0244\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0306\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0356\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5113e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.7813e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.4270e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.6607e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.7620e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.8766e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0315e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.3391e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.0702e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8444e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.5189e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.5148e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.5042e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.3678e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2861e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1484e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.9578e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.7296e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5305e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.4427e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2931e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.2776e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.1384e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1210e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.0835e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.9309e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 7.3717e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.2474e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3286e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.9101e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.2923e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.8725e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.6442e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.4581e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.3702e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3420e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2941e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2851e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.1976e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.0765e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.8523e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.7772e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8613e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.7778e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7269e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6220e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4865e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4876e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5012e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3848e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4400e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5291e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5139e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4046e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0696\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0342\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.1988e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.4694e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.1801e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5668e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0236e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.5832e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2947e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.3155e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.4428e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5426e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.5816e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.3894e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1398e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.9058e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8953e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.9863e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.8974e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.8275e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7132e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5411e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5544e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5982e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5007e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4228e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4837e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4908e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4615e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4383e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3183e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3435e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4935e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4537e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2805e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2018e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2602e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4360e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4179e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2845e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2086e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.2770e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2316e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2299e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2102e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2417e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2085e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3028e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2783e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1629e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1601e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2206e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2203e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2324e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1585e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2276e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2873e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3146e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1874e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1772e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1492e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2448e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2475e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1683e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0528e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2005e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2513e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2228e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1760e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1640e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1257e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1573e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1510e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2276e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2354e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1933e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1113e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1810e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2124e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2107e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1866e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1889e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1592e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1708e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1092e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1534e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1909e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2243e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1695e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5071\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5071\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5070\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5070\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5070\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5070\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5070\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5070\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5070\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5070\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5070\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5070\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5070\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5070\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5070\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5070\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5069\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5069\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5069\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5069\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5069\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5069\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5069\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5069\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3773\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 15.4350\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 15.3773\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15.3772\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 15.3772\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3770\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3769\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3768\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3767\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 15.3766\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 15.3764\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 15.3763\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3761\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 15.3760\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15.3759\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 15.3757\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15.3755\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 15.3754\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15.3752\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15.3750\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3749\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 15.3747\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 15.3745\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3743\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 15.3742\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15.3740\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15.3738\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 15.3736\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 15.3735\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 15.3733\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2245\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2311\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2247\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2248\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2248\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2248\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2247\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2247\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.2246\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2245\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2244\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.2243\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.2242\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.2241\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.2240\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2238\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.2237\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2235\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.2234\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2232\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.2230\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2228\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2227\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.2225\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.2223\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.2221\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2219\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.2218\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2216\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2214\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0021\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0012\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.4437e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9809e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.4819e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0010\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0011\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.4238e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.4964e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.5217e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.6582e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.0035e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.8574e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.8252e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9265e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9350e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7931e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.3451e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.7670e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.1862e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.7181e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.3785e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1272e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.9384e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.7521e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.4650e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1211e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7984e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.7560e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7607e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.9819e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1322e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1850e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2296e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1451e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0894e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.9644e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.8578e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8220e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.7769e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.6539e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4751e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4121e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3242e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4075e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5295e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5870e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5028e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4119e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3404e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3546e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3068e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3108e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2781e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2622e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2734e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3485e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2754e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1832e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2095e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2796e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2528e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1161e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1518e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2360e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3128e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3102e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2178e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2283e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2264e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2820e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2300e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2593e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2038e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1592e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2296e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2122e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1803e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1754e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1178e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1501e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1887e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1553e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0577e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0973e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1420e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2362e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2304e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1659e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1581e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1767e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1224e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1467e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1699e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2169e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2412e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2363e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1825e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1772e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1484e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2172e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2280e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2123e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1733e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1384e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1822e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1889e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1894e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1943e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1184e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1211e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1268e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1807e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1310e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1214e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1581e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1989e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2100e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1591e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1124e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1389e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1928e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2112e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1741e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1635e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1526e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2268e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1740e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1529e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1598e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2122e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2062e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1720e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1195e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1047e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1727e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2578e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2351e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1673e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1246e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2160e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1948e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1881e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1585e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1338e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1393e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0987e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0881e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1129e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1370e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2255e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2101e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2128e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1590e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1453e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1614e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2710e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1886e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1620e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1977e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1747e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1958e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1814e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1166e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1353e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2249e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2223e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0862e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1034e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0701e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1375e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1963e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1899e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1410e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1071e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1512e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1960e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2234e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1975e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2109e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2391e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1896e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1565e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1022e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1775e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2298e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2198e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1370e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0765e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1212e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1990e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1689e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2317e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2036e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1697e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1751e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2222e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1572e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1518e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1555e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1674e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2081e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1328e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0633e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0933e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1600e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2321e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2166e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1774e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1255e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1944e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1422e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2054e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1871e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1935e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2439e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2220e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1527e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0979e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1297e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1990e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2110e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1995e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1205e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1253e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1585e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1872e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1765e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1551e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0975e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0927e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1168e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1664e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1658e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1349e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1363e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2072e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1721e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1417e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1138e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2035e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2070e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1374e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1360e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1461e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1532e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2058e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1859e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1929e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1998e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2192e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1690e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2339e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1695e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1457e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1858e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2109e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1594e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0938e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0568e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0773e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1483e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1754e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1026e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1157e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1553e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1963e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1607e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1690e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1409e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2045e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1717e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1109e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1450e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1469e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1609e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2317e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1868e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1438e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1463e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1839e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1917e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2065e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1438e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1655e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1896e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1689e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1387e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1054e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0949e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1648e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1804e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1900e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0920e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1080e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1417e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2346e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2389e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1302e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0618e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0949e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1225e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1543e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1191e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1927e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2529e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2119e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1175e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1238e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1370e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2367e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2187e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2047e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1551e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0780e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1369e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2052e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1805e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1514e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1524e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1771e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1678e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1560e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0872e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1335e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1718e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1840e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2021e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1515e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0659e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1209e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1124e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1283e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1211e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1488e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1648e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1923e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1695e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1538e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1855e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2171e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1343e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1495e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0791e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0930e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1502e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1538e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1270e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1634e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1455e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1753e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2042e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2406e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1890e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1454e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1605e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1705e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1972e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2167e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1713e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1860e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1602e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1777e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1407e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1550e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1714e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2355e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2020e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1771e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1825e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1876e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1642e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1504e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0945e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1566e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2057e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1848e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1915e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2100e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0796e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1350e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1882e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1822e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0789e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0777e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1661e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2100e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1604e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1362e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0984e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1654e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1611e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1909e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1747e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1440e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1984e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2296e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1450e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1445e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1331e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1484e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1252e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1553e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1139e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0871e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1195e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1901e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1402e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1427e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1308e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1539e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1805e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1608e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0761e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1076e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1580e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2336e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2023e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1208e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0595e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1817e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1615e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1395e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1376e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1449e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1905e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2133e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1332e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1296e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1645e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2010e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1763e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1924e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1114e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1347e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1690e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1642e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1497e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1580e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0922e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0905e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1476e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1462e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0655e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0759e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1169e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2156e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2183e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2012e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1751e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2172e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1918e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1790e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1519e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1497e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.1023e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1456e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1555e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1366e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1342e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1757e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1358e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1553e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0844e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1271e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1897e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1713e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1278e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1002e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0671e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1579e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1839e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1521e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0742e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1155e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1706e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2151e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2079e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1704e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1322e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1722e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1797e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1524e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1323e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1354e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1481e-04\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2195e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1454e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1272e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1283e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1620e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1163e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1626e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1319e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1207e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1751e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2036e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1708e-04\n",
      "(1, 16780, 1)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1207e-04\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0783e-04\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1630e-04\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1639e-04\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1413e-04\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1097e-04\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1704e-04\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2029e-04\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2092e-04\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1938e-04\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1481e-04\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0786e-04\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1549e-04\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1311e-04\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1293e-04\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1483e-04\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1720e-04\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1944e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1782e-04\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1252e-04\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2045e-04\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1738e-04\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1706e-04\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1780e-04\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1512e-04\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0641e-04\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0462e-04\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1061e-04\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1540e-04\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1328e-04\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reg_data.columns)):\n",
    "    sampl = batch_sample[i].reshape((1,batch_sample.shape[1],batch_sample.shape[2]))\n",
    "    print(sampl.shape)\n",
    "    labl = batch_label[i].reshape((batch_label.shape[1],batch_label.shape[2]))\n",
    "    model.fit(sampl,\n",
    "                          labl,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "URqDB0oxhX_X",
    "outputId": "35e8073b-7b4e-4098-f5e7-0f000124a0ce"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-e5fe86a67178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_test_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_test_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mbatch_test_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_test_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_test_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sinewave'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mbatch_test_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_test_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_test_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mbatch_test_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_test_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_test_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sine' is not defined"
     ]
    }
   ],
   "source": [
    "                 \"\"\"Testing with random interval(DeepAnT)\"\"\"\n",
    "# Set number of test sequences \n",
    "n_test_seq = 1\n",
    "\n",
    "# Split a univariate sequence into samples\n",
    "def generate_test_batch(raw_seq, n_test_seq):\n",
    "  # Sample a portion of the raw_seq randomly\n",
    "    ran_ix = random.randint(0,len(raw_seq) - n_test_seq * w - n_test_seq * p_w)\n",
    "    raw_test_seq = array(raw_seq[ran_ix:ran_ix + n_test_seq * w +  n_test_seq * p_w])\n",
    "    batch_test_seq, batch_test_label = list(), list()\n",
    "    ix = ran_ix\n",
    "    for i in range(n_test_seq):\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = raw_seq[ix : ix+w],\n",
    "        seq_y = raw_seq[ix+w : ix+w+p_w]\n",
    "        ix = ix+w+p_w\n",
    "        batch_test_seq.append(seq_x)\n",
    "        batch_test_label.append(seq_y)\n",
    "    return array(batch_test_seq), array(batch_test_label)\n",
    "\n",
    "batch_test_seq, batch_test_label = generate_test_batch(list(df_sine['sinewave']), n_test_seq)\n",
    "batch_test_seq = batch_test_seq.reshape((batch_test_seq.shape[0], w, n_features))\n",
    "batch_test_label = batch_test_label.reshape((batch_test_label.shape[0], p_w))\n",
    "\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "model.evaluate(x=batch_test_seq,\n",
    "               y=batch_test_label,\n",
    "               verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK0_Cq-Oh0tC"
   },
   "outputs": [],
   "source": [
    "               \"\"\"Save Weights (DeepAnT)\"\"\"\n",
    "# save it to disk so we can load it back up anytime\n",
    "model.save_weights('ch_1_weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jpzknk4th9bU",
    "outputId": "ab1c4808-b829-4bd7-8d65-2e273a6e70b1"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'sinwave_DeepAnT_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-c387e5f76da0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Load the model's saved weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sinwave_DeepAnT_1.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Sample a portion of the raw_seq randomly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'sinwave_DeepAnT_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "            \"\"\"Predicting random intervals (DeepAnT)\"\"\"\n",
    "# Build model \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('sinwave_DeepAnT_1.h5')\n",
    "          \n",
    "# Sample a portion of the raw_seq randomly\n",
    "# 1. Choose \n",
    "ran_ix = random.randint(1,len(raw_seq) - w - p_w)\n",
    "input_seq = array(raw_seq[ran_ix : ran_ix + w])\n",
    "target_seq = array(raw_seq[ran_ix + w : ran_ix + w + p_w])\n",
    "input_seq = input_seq.reshape((1, w, n_features))\n",
    "\n",
    "# Predict the next time stampes of the sampled sequence\n",
    "yhat = model.predict(input_seq, verbose=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(yhat)\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(target_seq) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2-oM2iL1gw4Q",
    "outputId": "a8ac362e-fccd-4d6c-f946-386a27620206"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'sinwave_DeepAnT_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bede577c6591>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Load the model's saved weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sinwave_DeepAnT_1.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'sinwave_DeepAnT_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "            \"\"\"Predicting future sequence (DeepAnT)\"\"\"\n",
    "# Build model \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('sinwave_DeepAnT_1.h5')\n",
    "          \n",
    "    \n",
    "raw_seq = list(df_sine['sinewave'])\n",
    "endix = len(raw_seq) - w - p_w\n",
    "input_seq = array(raw_seq[endix:endix+w])\n",
    "target_seq = array(raw_seq[endix+w:endix+w+p_w]) \n",
    "input_seq = input_seq.reshape((1, w, n_features))\n",
    "\n",
    "# Predict the next time stampes of the sampled sequence\n",
    "predicted_seq = model.predict(input_seq, verbose=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(predicted_seq)\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(target_seq) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "664VO9gMmmFE",
    "outputId": "0f8b7983-5c1c-4b94-d898-865d8f0fc0fd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-72e3ac65ab28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m'''Visualization of predicted time series'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0min_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sinewave'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mendix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mendix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtar_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sinewave'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mendix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mendix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mp_w\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredicted_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf_sine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mendix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mendix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mp_w\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredicted_seq\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sine' is not defined"
     ]
    }
   ],
   "source": [
    "           '''Visualization of predicted time series'''\n",
    "in_seq = df_sine['sinewave'][endix:endix+w]\n",
    "tar_seq = df_sine['sinewave'][endix+w:endix+w+p_w]\n",
    "predicted_seq = predicted_seq.reshape((p_w))\n",
    "d = {'time': df_sine['time'][endix+w:endix+w+p_w], 'values': predicted_seq}\n",
    "df_sine_pre = pd.DataFrame(data=d)\n",
    "pre_seq = df_sine_pre['values']\n",
    "\n",
    "plt.plot(in_seq)\n",
    "plt.plot(tar_seq)\n",
    "plt.plot(pre_seq)\n",
    "plt.title('sinewave prediction')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('time')\n",
    "plt.legend(['input_seq', 'target_seq', 'pre_seq'], loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([endix,endix+w+p_w])\n",
    "fig_predict = plt.figure(figsize=(100,10))\n",
    "fig_predict.savefig('predicted_sequence.png')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "no2SqYbNoPXG",
    "outputId": "6925ffa8-9a85-4f10-99a9-f6dedb408878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smoor\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 17.2053\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 17.0966\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 16.9761\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 16.8562\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 993us/step - loss: 16.7356\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 16.6270\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 16.5264\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 16.4241\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 16.3190\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 16.2092\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 607us/step - loss: 16.1016\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 593us/step - loss: 15.9974\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 397us/step - loss: 15.8933\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 393us/step - loss: 15.7906\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15.6849\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 15.5822\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 15.4773\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 15.3700\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 15.2653\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 15.1587\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 15.0502\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.9373\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 603us/step - loss: 14.8196\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 14.6943\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 603us/step - loss: 14.5655\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 14.5582\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 14.5307\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 14.4745\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 392us/step - loss: 14.4126\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 407us/step - loss: 14.3158\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 14.2145\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 14.1030\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14.0130\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.9792\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 13.9313\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.8699\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.7957\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 13.7098\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.6142\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 602us/step - loss: 13.6379\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 598us/step - loss: 13.6961\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.7051\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 598us/step - loss: 13.6554\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 13.5916\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.5411\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.4776\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.4005\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.4080\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 13.3998\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 13.3717\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.3256\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.3042\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.2937\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 13.2638\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.2164\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 13.1526\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.0745\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 13.0376\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 13.0512\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 13.0499\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 13.0284\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 12.9891\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 12.9335\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 598us/step - loss: 12.8635\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 12.8405\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 12.8000\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.7635\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 12.7504\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 12.7163\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.6628\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 12.5927\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.5598\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.5380\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 12.5204\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 12.4844\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 12.4319\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.3730\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 12.3187\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 12.2883\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.2496\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 12.2030\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.1638\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.1158\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 12.0658\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 12.0553\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.9779\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 11.9727\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.9577\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.9122\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 11.8390\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 11.7464\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 11.7082\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.6818\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 11.6422\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 11.5736\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 11.5734\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.5029\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.4797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 11.4383\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 11.3941\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 11.3405\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 11.2914\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 402us/step - loss: 11.2523\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 11.2085\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 11.1756\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 11.1256\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.0851\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 11.0343\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 10.9816\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.9293\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.8909\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.8347\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 10.7839\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.7418\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.6785\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 10.6541\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.6045\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.5355\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.4735\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 10.4210\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.3642\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.3116\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 10.2483\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 10.1974\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 10.1304\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 10.0791\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 10.0266\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 9.9614\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 9.8853\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 9.8194\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 9.7534\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 9.6822\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 9.6192\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 9.5430\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 9.4686\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 9.3865\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 9.3227\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 9.2440\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 9.1683\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 9.0809\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 9.0142\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 8.9331\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 8.8414\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 8.7638\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 8.6742\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 8.6017\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 8.4985\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 8.4409\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 8.3515\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 8.2410\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 8.1567\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 8.0635\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 7.9537\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 7.8649\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 7.7595\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 7.6628\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 7.5473\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 7.4704\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 7.3782\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.2698\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 7.1428\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 7.0057\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 6.8882\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 6.7987\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.6596\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 6.5392\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 6.4464\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 6.3285\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 6.2317\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 6.1117\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 5.9709\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 5.8111\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 5.8159\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 5.5678\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 201us/step - loss: 5.4750\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 5.3656\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 5.2314\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 5.0762\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 4.9417\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 4.8500\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 4.6877\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 4.5375\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 4.4358\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 4.3637\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 4.1942\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 4.0479\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 4.0144\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 3.8239\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 3.7314\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 3.5965\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 3.6480\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 3.5731\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.4655\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 3.4285\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 3.3770\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 3.3415\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.2333\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.1555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 3.0994\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0309\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.9497\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.9218\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.8714\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 2.7751\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.7752\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.6831\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.5821\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.5369\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 2.4506\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.4100\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.3620\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.2840\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 2.2291\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.1919\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 2.1486\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.1008\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 2.0923\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0916\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0603\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 2.0671\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.1165\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 2.0979\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 2.0644\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 2.0854\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0439\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0779\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 2.0981\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0899\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0586\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 2.0045\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0912\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.9731\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0713\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0544\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9872\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.9414\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9414\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9862\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9602\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.9959\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9564\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9611\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.9369\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9646\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8994\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0111\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9114\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.1099\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0535\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.9640\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 1.9541\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0117\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 2.0281\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 1.9677\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0801\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.9172\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 1.9575\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.9326\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9239\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0615\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9801\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0386\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0652\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8577\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9532\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.9572\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.8912\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 2.0003\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9542\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.9958\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0213\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 1.8598\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8911\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9245\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9216\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.9050\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9518\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0388\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9256\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9392\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.9996\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.8610\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9287\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7963\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 398us/step - loss: 1.9056\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.8307\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8878\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8995\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7740\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.9798\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7769\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8937\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9759\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.8487\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8535\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7954\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8291\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7315\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8946\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.7569\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.9396\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0240\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.9041\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7803\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8601\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7428\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8862\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9450\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8217\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.7299\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0278\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8272\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8901\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0712\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 2.0489\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8608\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.8612\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 1.9997\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.9376\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7506\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9409\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 2.0280\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 397us/step - loss: 1.9347\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.7603\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0258\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9830\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7774\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 1.9161\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9254\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7598\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8561\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 2.0098\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.8025\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8244\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9449\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.8817\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7284\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7537\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6827\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7915\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8114\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7400\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.8324\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8532\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7333\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8569\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8343\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.6829\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.8845\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9685\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8642\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.6953\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8349\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.8461\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6986\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7940\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7341\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7722\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.8833\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.8234\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6684\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8472\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7467\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.6682\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7166\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6751\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6855\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6605\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6873\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7562\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6961\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6500\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 603us/step - loss: 1.8434\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.6636\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7812\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8706\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7924\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.6711\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7541\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.7040\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.6546\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7079\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 1.6719\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7587\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7312\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6469\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7006\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6512\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.7374\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7548\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6846\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7792\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.8070\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.6790\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.7051\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 398us/step - loss: 1.6720\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 398us/step - loss: 1.6287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6448\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.6052\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7944\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5939\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6558\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6429\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6307\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6345\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6098\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.6206\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5918\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5798\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 1.5767\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5946\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5926\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5820\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.5665\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5711\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6128\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6326\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.7035\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.6190\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7115\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6022\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6510\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.6784\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 449us/step - loss: 1.5538\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.7973\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6958\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6827\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8337\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7384\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6123\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 401us/step - loss: 1.8054\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6345\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 1.7463\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.9370\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.8759\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6337\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.8544\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9601\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 1.6284\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.8285\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 2.0714\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 2.0609\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8287\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5868\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.9430\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.9911\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6641\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7132\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.8913\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.8443\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.6469\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7145\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.9149\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7090\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.6733\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 403us/step - loss: 1.8736\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.8817\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.7507\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5890\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.7734\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6783\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6383\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7772\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.7769\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6542\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5834\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.6381\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5595\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5661\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5734\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5705\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5552\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5792\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5344\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5895\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5895\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5843\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.6052\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5567\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5542\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5579\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 1.5940\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 1.5743\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5987\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5479\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.5462\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 603us/step - loss: 1.5477\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.5384\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5457\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5026\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4924\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.4956\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.5062\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.4951\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 1.4913\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 1.5052\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.4875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.4914\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 1.4928\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "[[ 93.776695 -81.86888 ]]\n"
     ]
    }
   ],
   "source": [
    "# Shallow CNN version  \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [-5, 5, -10, 10, -15, 15, -20, 20, -25]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=1)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=1)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFv7f2x-euPk"
   },
   "outputs": [],
   "source": [
    "               \"\"\"Save Weights (ShallowAnT)\"\"\"\n",
    "# save it to disk so we can load it back up anytime\n",
    "model.save_weights('shallow_ch_1_weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determins whether a sequence exceeds the threshold for being an anomaly\n",
    "\n",
    "return boolean value of whether the sequence is an anomaly or not\n",
    "\"\"\"\n",
    "def anomaly_detector(prediction_seq, ground_truth_seq):\n",
    "    # calculate Euclidean between actual seq and predicted seq\n",
    "    dist = np.linalg.norm(ground_truth_seq - prediction_seq)  \n",
    "    if (dist > anm_det_thr):\n",
    "        return true  # anomaly\n",
    "    else:\n",
    "        return false # normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda6f2bec422dd747988837f1b049720b89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
