{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60oNtF4FWakJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling1D, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9A1LKB0GwtQH"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCvn51nkpuah"
   },
   "outputs": [],
   "source": [
    "              \"\"\"Hyperparameters\"\"\"\n",
    "w = 2000                 # History window (number of time stamps taken into account) \n",
    "                         # i.e., filter(kernel) size       \n",
    "p_w = 300                # Prediction window (number of time stampes required to be \n",
    "                         # predicted)\n",
    "n_features = 1           # Univariate time series\n",
    "\n",
    "kernel_size = 2          # Size of filter in conv layers\n",
    "num_filt_1 = 32          # Number of filters in first conv layer\n",
    "num_filt_2 = 32          # Number of filters in second conv layer\n",
    "num_nrn_dl = 40          # Number of neurons in dense layer\n",
    "num_nrn_ol = p_w         # Number of neurons in output layer\n",
    "\n",
    "conv_strides = 1\n",
    "pool_size_1 = 2          # Length of window of pooling layer 1\n",
    "pool_size_2 = 2          # Length of window of pooling layer 2\n",
    "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
    "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
    "\n",
    "epochs = 30\n",
    "dropout_rate = 0.5       # Dropout rate in the fully connected layer\n",
    "learning_rate = 2e-5  \n",
    "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "aKYzBd94KZFu",
    "outputId": "52cfaed6-92e1-42ab-8ce8-9e4af7cf69b2"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Sample Data loading\n",
    "\"\"\"\n",
    "df_sine = pd.read_csv('https://raw.githubusercontent.com/swlee23/Deep-Learning-Time-Series-Anomaly-Detection/master/data/sinewave.csv')\n",
    "plt.plot(df_sine['sinewave'])\n",
    "plt.title('sinewave')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('time')\n",
    "plt.legend(['sinewave'], loc='upper right')\n",
    "plt.figure(figsize=(100,10))\n",
    "plt.show()\n",
    "df_sine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdf_helper import *\n",
    "from stat_helper import *\n",
    "from data_cleaning import *\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'competitionfiles/COOLCAT_20091219_074253_24_20091219_074253_240.hdf'\n",
    "df = h5_to_df(path).reset_index(drop=True)\n",
    "\n",
    "columns = df.columns\n",
    "x = np.array(df, '>i4') # big endian\n",
    "newx = x.byteswap().newbyteorder()\n",
    "df = pd.DataFrame(newx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reduce_dataset_size(df, cluster_size = 50)\n",
    "df = smooth_values(df)\n",
    "df = pd.DataFrame(robust_scaling(df))\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQsOxuDCIGpQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data preprocessing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + w\n",
    "        out_end_ix = end_ix + p_w\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = list(df['ch_1'])\n",
    "\n",
    "# split into samples\n",
    "batch_sample, batch_label = split_sequence(raw_seq)\n",
    "\n",
    "# summarize the data\n",
    "# for i in range(5):\n",
    "#     print(X[i], Y[i])\n",
    "  \n",
    "# 2. reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "\n",
    "# need to convert batch into 3D tensor of the form [batch_size, input_seq_len, n_features]\n",
    "batch_sample = batch_sample.reshape((batch_sample.shape[0], batch_sample.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "colab_type": "code",
    "id": "sLBqHZLmomSD",
    "outputId": "375909cf-8a14-4e10-aa93-7d5d2fac440a"
   },
   "outputs": [],
   "source": [
    "              \"\"\"Generate model for predictor\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer #1\n",
    "# Computes 32 features using a 1D filter(kernel) of with w with ReLU activation. \n",
    "# Padding is added to preserve width.\n",
    "# Input Tensor Shape: [batch_size, w, 1] / batch_size = len(batch_sample)\n",
    "# Output Tensor Shape: [batch_size, w, num_filt_1] (num_filt_1 = 32 feature vectors)\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "\n",
    "# Pooling Layer #1\n",
    "# First max pooling layer with a filter of length 2 and stride of 2\n",
    "# Input Tensor Shape: [batch_size, w, num_filt_1]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1]\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "                    #  strides=pool_strides_1, \n",
    "                    #  padding='valid'))\n",
    "\n",
    "# Convolutional Layer #2\n",
    "# Computes 64 features using a 5x5 filter.\n",
    "# Padding is added to preserve width and height.\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, 32]\n",
    "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "# Max Pooling Layer #2\n",
    "# Second max pooling layer with a 2x2 filter and stride of 2\n",
    "# Input Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "                    #  strides=pool_strides_2, \n",
    "                    #  padding='valid'\n",
    "          \n",
    "# Flatten tensor into a batch of vectors\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer (Output layer)\n",
    "# Densely connected layer with 1024 neurons\n",
    "# Input Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
    "# Output Tensor Shape: [batch_size, 1024]\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu'))  \n",
    "\n",
    "# Dropout\n",
    "# Prevents overfitting in deep neural networks\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Output layer\n",
    "# Input Tensor Shape: [batch_size, 1024]\n",
    "# Output Tensor Shape: [batch_size, p_w]\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Summarize model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "K76R-2HPajxI",
    "outputId": "b138835d-a0e7-4af7-a1fd-53b18446258a"
   },
   "outputs": [],
   "source": [
    "                 '''configure model'''\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_absolute_error')\n",
    "\n",
    "# sgd = keras.optimizers.SGD(lr=learning_rate, \n",
    "#                          decay=1e-6, \n",
    "#                          momentum=0.9, \n",
    "#                          nesterov=True)\n",
    "# model.compile(optimizer='sgd', \n",
    "#               loss='mean_absolute_error', \n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MO8EMSBaMZ8K",
    "outputId": "7c033331-7d5e-473c-ac81-5c7971db6fa4"
   },
   "outputs": [],
   "source": [
    "                    '''Training'''\n",
    "model_fit = model.fit(batch_sample,\n",
    "                      batch_label,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "URqDB0oxhX_X",
    "outputId": "35e8073b-7b4e-4098-f5e7-0f000124a0ce"
   },
   "outputs": [],
   "source": [
    "                 \"\"\"Testing with random interval(DeepAnT)\"\"\"\n",
    "# Set number of test sequences \n",
    "n_test_seq = 1\n",
    "\n",
    "# Split a univariate sequence into samples\n",
    "def generate_test_batch(raw_seq, n_test_seq):\n",
    "  # Sample a portion of the raw_seq randomly\n",
    "    ran_ix = random.randint(0,len(raw_seq) - n_test_seq * w - n_test_seq * p_w)\n",
    "    raw_test_seq = array(raw_seq[ran_ix:ran_ix + n_test_seq * w +  n_test_seq * p_w])\n",
    "    batch_test_seq, batch_test_label = list(), list()\n",
    "    ix = ran_ix\n",
    "    for i in range(n_test_seq):\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = raw_seq[ix : ix+w],\n",
    "        seq_y = raw_seq[ix+w : ix+w+p_w]\n",
    "        ix = ix+w+p_w\n",
    "        batch_test_seq.append(seq_x)\n",
    "        batch_test_label.append(seq_y)\n",
    "    return array(batch_test_seq), array(batch_test_label)\n",
    "\n",
    "batch_test_seq, batch_test_label = generate_test_batch(list(df_sine['sinewave']), n_test_seq)\n",
    "batch_test_seq = batch_test_seq.reshape((batch_test_seq.shape[0], w, n_features))\n",
    "batch_test_label = batch_test_label.reshape((batch_test_label.shape[0], p_w))\n",
    "\n",
    "# Returns the loss value & metrics values for the model in test mode\n",
    "model.evaluate(x=batch_test_seq,\n",
    "               y=batch_test_label,\n",
    "               verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK0_Cq-Oh0tC"
   },
   "outputs": [],
   "source": [
    "               \"\"\"Save Weights (DeepAnT)\"\"\"\n",
    "# save it to disk so we can load it back up anytime\n",
    "model.save_weights('ch_1_weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jpzknk4th9bU",
    "outputId": "ab1c4808-b829-4bd7-8d65-2e273a6e70b1"
   },
   "outputs": [],
   "source": [
    "            \"\"\"Predicting random intervals (DeepAnT)\"\"\"\n",
    "# Build model \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('sinwave_DeepAnT_1.h5')\n",
    "          \n",
    "# Sample a portion of the raw_seq randomly\n",
    "# 1. Choose \n",
    "ran_ix = random.randint(1,len(raw_seq) - w - p_w)\n",
    "input_seq = array(raw_seq[ran_ix : ran_ix + w])\n",
    "target_seq = array(raw_seq[ran_ix + w : ran_ix + w + p_w])\n",
    "input_seq = input_seq.reshape((1, w, n_features))\n",
    "\n",
    "# Predict the next time stampes of the sampled sequence\n",
    "yhat = model.predict(input_seq, verbose=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(yhat)\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(target_seq) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2-oM2iL1gw4Q",
    "outputId": "a8ac362e-fccd-4d6c-f946-386a27620206"
   },
   "outputs": [],
   "source": [
    "            \"\"\"Predicting future sequence (DeepAnT)\"\"\"\n",
    "# Build model \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=num_filt_1,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 input_shape=(w, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
    "model.add(Conv1D(filters=num_filt_2,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=conv_strides,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(units=num_nrn_ol))\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model.load_weights('sinwave_DeepAnT_1.h5')\n",
    "          \n",
    "    \n",
    "raw_seq = list(df_sine['sinewave'])\n",
    "endix = len(raw_seq) - w - p_w\n",
    "input_seq = array(raw_seq[endix:endix+w])\n",
    "target_seq = array(raw_seq[endix+w:endix+w+p_w]) \n",
    "input_seq = input_seq.reshape((1, w, n_features))\n",
    "\n",
    "# Predict the next time stampes of the sampled sequence\n",
    "predicted_seq = model.predict(input_seq, verbose=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(predicted_seq)\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(target_seq) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "664VO9gMmmFE",
    "outputId": "0f8b7983-5c1c-4b94-d898-865d8f0fc0fd"
   },
   "outputs": [],
   "source": [
    "           '''Visualization of predicted time series'''\n",
    "in_seq = df_sine['sinewave'][endix:endix+w]\n",
    "tar_seq = df_sine['sinewave'][endix+w:endix+w+p_w]\n",
    "predicted_seq = predicted_seq.reshape((p_w))\n",
    "d = {'time': df_sine['time'][endix+w:endix+w+p_w], 'values': predicted_seq}\n",
    "df_sine_pre = pd.DataFrame(data=d)\n",
    "pre_seq = df_sine_pre['values']\n",
    "\n",
    "plt.plot(in_seq)\n",
    "plt.plot(tar_seq)\n",
    "plt.plot(pre_seq)\n",
    "plt.title('sinewave prediction')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('time')\n",
    "plt.legend(['input_seq', 'target_seq', 'pre_seq'], loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([endix,endix+w+p_w])\n",
    "fig_predict = plt.figure(figsize=(100,10))\n",
    "fig_predict.savefig('predicted_sequence.png')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "no2SqYbNoPXG",
    "outputId": "6925ffa8-9a85-4f10-99a9-f6dedb408878"
   },
   "outputs": [],
   "source": [
    "# Shallow CNN version  \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [-5, 5, -10, 10, -15, 15, -20, 20, -25]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=1)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=1)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFv7f2x-euPk"
   },
   "outputs": [],
   "source": [
    "               \"\"\"Save Weights (ShallowAnT)\"\"\"\n",
    "# save it to disk so we can load it back up anytime\n",
    "model.save_weights('shallow_ch_1_weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determins whether a sequence exceeds the threshold for being an anomaly\n",
    "\n",
    "return boolean value of whether the sequence is an anomaly or not\n",
    "\"\"\"\n",
    "def anomaly_detector(prediction_seq, ground_truth_seq):\n",
    "    # calculate Euclidean between actual seq and predicted seq\n",
    "    dist = np.linalg.norm(ground_truth_seq - prediction_seq)  \n",
    "    if (dist > anm_det_thr):\n",
    "        return true  # anomaly\n",
    "    else:\n",
    "        return false # normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda6f2bec422dd747988837f1b049720b89"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
